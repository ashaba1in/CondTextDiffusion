{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08bc2b8-e050-4cd7-b536-d3199948fe8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ff3d33-9db9-449b-9351-512ff3a9f792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertLMHeadModel, BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bdfa62-47e8-45f4-899f-e79fcbcc9afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.dataset import WikipediaDatasetDDP\n",
    "from estimation_utils.metrics import BloomMetricConditional, BloomMetric\n",
    "from utils.util import dict_to_cuda, set_seed\n",
    "from estimation_utils.util import compute_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b1345a-3a37-45f8-b24b-d663e1ea9a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73503df2-48d8-4516-ba6b-2e68ba1d8455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b79befa-81a8-4eae-821b-e38cf3a2b26c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee755deecfc41468c7b8f7d80fd8a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset tokenization (num_proc=30):   0%|          | 0/38661 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = next(WikipediaDatasetDDP(\n",
    "    split=\"valid\",\n",
    "    tokenizer_bert=tokenizer,\n",
    "    tokenizer_cond=tokenizer,\n",
    "    tokenizer_gen=tokenizer,\n",
    "    max_sequence_len=64,\n",
    "    pos_begin=0.,\n",
    "    pos_end=0.67,\n",
    ").get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a8b69da-a931-4f63-a1a5-82a5d65d62ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=1,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0eac0f-8d30-4277-b1a0-1e293b9cfdc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f27da9-9c3d-45c2-b4d8-1f2b91fcb304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpt2 == gpt2-small\n",
    "generator_gpt2 = pipeline('text-generation', model='gpt2', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e37695a-aa2a-4d32-b3d6-3fca44fc60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text_cond, max_length, num_beams=1):\n",
    "    texts_gpt = generator_gpt2(\n",
    "        text_cond,\n",
    "        max_new_tokens=max_length, \n",
    "        num_return_sequences=1,\n",
    "        return_full_text=False, \n",
    "        pad_token_id=50256,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "    \n",
    "    return [l[0][\"generated_text\"] for l in texts_gpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9251192-3fd4-4fb7-bd7c-e2adc7bdb9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_texts = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be0de6b7-683a-404e-acb0-c0dfd8a40a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/303 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  0%|          | 1/303 [01:06<5:35:19, 66.62s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "  0%|          | 1/303 [01:43<8:38:27, 103.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m text_cond \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m      7\u001b[0m     X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      8\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m text_target \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m     12\u001b[0m     X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m     13\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m total_gen_texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m total_cond_texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_cond\n\u001b[1;32m     18\u001b[0m num_texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(text_cond)\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mgenerate_text\u001b[0;34m(text_cond, max_length, num_beams)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(text_cond, max_length, num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     texts_gpt \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator_gpt2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_full_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [l[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m texts_gpt]\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/pipelines/text_generation.py:201\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/pipelines/base.py:1100\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1097\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1098\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[0;32m-> 1100\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/pipelines/base.py:1025\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1024\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1025\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/pipelines/text_generation.py:263\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/generation/utils.py:1565\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1558\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1559\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1560\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1562\u001b[0m     )\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/generation/utils.py:2612\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2609\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2611\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2612\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2620\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:1076\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1076\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1091\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:900\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    890\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    891\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    892\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    897\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    898\u001b[0m     )\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 900\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:390\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    388\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    389\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 390\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    399\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:312\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    310\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    314\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    315\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/pytorch_utils.py:102\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    101\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[0;32m--> 102\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_texts = 0\n",
    "total_gen_texts = []\n",
    "total_cond_texts = []\n",
    "\n",
    "for X in tqdm(loader):\n",
    "    text_cond = tokenizer.batch_decode(\n",
    "        X[\"cond_ids\"], \n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    text_target = tokenizer.batch_decode(\n",
    "        X[\"input_ids\"], \n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "    \n",
    "    total_gen_texts += generate_text(text_cond, max_length=64)\n",
    "    total_cond_texts += text_cond\n",
    "    num_texts += len(text_cond)\n",
    "    if num_texts >= total_num_texts:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf65767b-f66c-49a3-9796-58d956663302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063b695-7a0c-478e-a80b-200a4ed884f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900781d-e571-45ef-8779-d4914015fa13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08ef0f-00fe-4d45-bd31-ae59ec748157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f96a8c24-ce6f-4a14-887f-315eda9b4999",
   "metadata": {},
   "source": [
    "## Условная метрика текста: BloomMetricConditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ce7631a-3e7b-400b-8aa6-3159154f44f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4258c4d4e31471d914a08169395e510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_bloom_fn = BloomMetricConditional(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "216e78c0-0ecb-4e3e-a4f1-2bd2680e0c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.12 s, sys: 89.2 ms, total: 9.21 s\n",
      "Wall time: 9.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "texts_gpt = generator_gpt2(\n",
    "        text_cond,\n",
    "        max_new_tokens=64, \n",
    "        num_return_sequences=1,\n",
    "        return_full_text=False, \n",
    "        pad_token_id=50256,\n",
    "        num_beams=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbed57bd-5393-4bf1-8e7b-5355b34c0a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the vibe was also made in tandem with a toyota model, the toyota matrix, at the nummi plant. the prizm along with its geo siblings suffered severe sales loss when the brand denomination changed from geo to chevrolet in 1998. the geo models outsold the rebadged chevrolets three to one.',\n",
       " \"0 may also refer to : one of king's greatest influences was the musician tom taylor, who gave king guitar lessons when king was 12.\",\n",
       " 'cornelius bolton ( – 16 september 1779 ) was an irish landowner and politician. biography. he was made a freeman of the city of waterford in 1737 and was mayor of waterford from 1743 to 1744 and in 1761. he represented the city in parliament',\n",
       " \"in an effort to create a more competitive field in organizers announced a series of changes to the championship. the most significant was that from the teams have had to run on pirelli control or'spec'tyres. the standard of dunlop and michelin that most of the teams had been using. dunlop looked to take\",\n",
       " 'the ships that attempted to evade it but also to discourage others. the blockade runners may have been numerous, but they were built for speed rather than the ability to carry cargo. the more conventional cargo vessels, and their spacious holds, went elsewhere. as a result, southern exports of cotton fell by 95 % from pre',\n",
       " 'early life. in 1946 leading english psychologist charles samuel',\n",
       " \"in both the manga and novel mayumi's corpse is the first object encountered by shuya outside of the school.\",\n",
       " 'references. & lt',\n",
       " \"scientist to one of s. h. i. e. l. d.'s most senior agents, also clocking significant experience as a field agent. she is distinguished from her colleagues by taking very determined and sometimes coldly rational decisions in the pursuit of what she believes is right. fictional character biography. i\",\n",
       " \"trio, formed in 2002 in saitama prefecture. the band's style resembles post - hardcore and progressive rock, math - rock, often incorporating rapid changes of tempo and mood framed in complex guitar melodies and technical drumming. they utilize both male and female vocals ranging from soft singing to loud wails and screams. biography\",\n",
       " 'served by milngavie railway station on the north clyde line of the spt rail network, which links it to central glasgow. in 2018 the scottish government published statistics for the town showing that the population increased to 13, 537 in 6, 062 households. the town is also a popular retirement location, with',\n",
       " 'under the pressure of their questioning, phelan eventually asserts to nicola that he thinks she is his daughter — explaining that he previously had an affair with her mother',\n",
       " 'awards ( selected ). 2014 - 2015 national endowment for the humanities faculty award & lt ; br & gt ; 2010 - 2011 american council of learned societies fellowship & lt ; br & gt ; 2010 - 2011 dibner fellowship in the history of science, huntington library & lt ; br & gt ;',\n",
       " \"rose bay whilst 24. 8 % have never been married. 38 % of families are couples with children, 47. 6 % are couples without children, and 13. 4 % are single - parent families. of people aged 15 or older in rose bay, the most common education level achieved is a bachelor's degree\",\n",
       " \"opposition ruckmen just couldn't get around him. i couldn't believe the size of his legs ; they were enormous. he could manoeuvre\",\n",
       " 'he was taken to chitwan by ambulance. the squadron flew a4']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7986ec54-edbe-4d4c-b3fe-5e1c8e28a534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': ' 2002. the prizm was replaced with the chevrolet prizm in 2004. the prizm was replaced with the chevrolet prizm in 2006. the prizm was replaced with the chevrolet prizm in 2007. the prizm was replaced with the chevrolet'}],\n",
       " [{'generated_text': ' still young. Tom taylor was also one of the first guitarists to play guitar in the U.S. and the first to write a song for a song.\\n\\nThe song \"King of the Blues\" was written by T.J. \"Buddy\" McLean and produced by William H. Smith'}],\n",
       " [{'generated_text': '. He was also a member of the council of the city of waterford and mayor of the city of Waterford from 1744 to 1745. He was also a member of the council of the city of waterford and mayor of the city of Waterford from 1745 to 1746. He was also a member'}],\n",
       " [{'generated_text': \" for the championship was that the teams had to run on pirelli control or'spec'tyres.\\n\\nThe changes were made to the championship in part to address the increasing number of teams competing on pirelli control.\\n\\nThe changes were made to the championship in part to address the increasing number of\"}],\n",
       " [{'generated_text': '\\n\\nThere are no known examples of ships sailing from the south to the north.\\n\\nThe following is a list of ships that have sailed from the south to the north in the last century.\\n\\n1. The HMS Queen Elizabeth\\n\\nThe Royal Navy has had a long history of sailing from the south to'}],\n",
       " [{'generated_text': ', Dr. William W. Loeffler of the University of California, Los Angeles, was awarded the Nobel Prize in Physiology or Medicine for his work in the field of neurology. Dr. Loeffler was one of the pioneers in the field of neurology and was a pioneer in the field of'}],\n",
       " [{'generated_text': ' result of a battle with the devil.\\n\\nIn the manga, the devil is described as a \"fairy\" with a horn on his head. In the novel, he is described as a \"fairy\" with a horn on his head. In the novel, he is described as a \"fairy\"'}],\n",
       " [{'generated_text': '\\n\\n}\\n\\n}\\n\\nstatic int main ( String [] args ) {\\n\\nint i = 0 ;\\n\\nfor ( int i = 0 ; i < args. size (); i ++ ) {\\n\\nif ( args [ i ]!= nullptr ) {\\n\\nargs [ i ] = null'}],\n",
       " [{'generated_text': '. e. t. i. e. s. r. i. e. r. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e'}],\n",
       " [{'generated_text': ' in tempo and dynamics. the band\\'s debut album, \"Gone,\" was released in 2010.\\n\\n\\nThe band also released its second full-length album, \"The Fall,\" in 2011. The band also released their third full-length album, \"The Fall,\" in 2012. The band also released their fourth'}],\n",
       " [{'generated_text': \" with many people living in the area.\\n\\nThe town has been described as a 'bogus' by some in the local community, who say that many of the town's residents are 'lazy, lazy, lazy, lazy, lazy, lazy, lazy, lazy, lazy, lazy, lazy, lazy\"}],\n",
       " [{'generated_text': ' a claim he denies.\\n\\n\"I don\\'t think she\\'s my daughter,\" nicola says. \"I think she\\'s my daughter.\"\\n\\nNicola\\'s mother, who is not named in the lawsuit, says her daughter did not speak to her about the incident.\\n\\nShe says she didn\\'t know'}],\n",
       " [{'generated_text': ' the humanities faculty award & lt ; br & gt ; 2010 - 2011 edinburgh, n.d. fellowship in the humanities faculty award & lt ; br & gt ; 2010 - 2011 greece fellowship in the humanities faculty award & lt ; br & gt ; 2010 - 2011 gree'}],\n",
       " [{'generated_text': \" degree or higher. of people aged 15 or older in rose bay, the most common education level achieved is a bachelor's degree or higher. of people aged 15 or older in rose bay, the most common education level achieved is a bachelor's degree or higher. of people aged 15 or older in rose bay, the most\"}],\n",
       " [{'generated_text': 'pees, which has risen by more than 30 per cent in the past year.\\n\\nThe government is also seeking to make it easier for foreign investors to buy shares in the company. It is also seeking to expand the number of employees in the company, which is expected to increase by 30 per cent this year.\\n'}],\n",
       " [{'generated_text': '\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFantastic\\n\\nFant'}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa4d71a-f59d-4da4-8dcb-fed75d02ab06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' if you don\\'t know what a geo model is, here\\'s a short rundown of its design and design history and how it came to be called \"Chevrolet\\'s\" real name.\\n\\nFirst the base unit, the geo system, uses the Geo, a 2,000 meter tall fiber optic transmission system with',\n",
       " \" taylor's guitar lessons helped win him a few Grammy Awards in the early-90s -- although he was a member of three bands named after the bass player Taylor's first violinist, Henry F. Taylor Jr.; his father (John Taylor Sr. and his son Tom) and musician Tambour\",\n",
       " ' and tried, succeeded to the second rank to the hilt for 16 months and served the king for 3 terms, until he was shot during the Battle of the Rhine. The city was not yet completely free of slavery until 1741; therefore and even though the early work and progress in the north took place in 17',\n",
       " \" advantage of the increased flow of the Pirelli practice facilities. michelin is a better technique of doing away with wet seats to provide more of a comfortable seating setup. the race schedule was changed to match that of the team's races. the pirelli Pirelli Management Team also added 3 pirelli\",\n",
       " '-war levels, and some of the former cotton mills in northern Germany experienced even lower output than the rest of the country. and in some cases of interest at the time the \"Rafaelo\" was being developed. (Source) by T. S. Switzer (T. I. W. N.',\n",
       " 'son and his partner began researching and analyzing an unspoken idea that, if humans were to learn to recognize and respond to human emotions we\\'d no longer be able to empathize with them at all unless we knew how to do it. They found that only a few hours after the \"wanting-recognition\" gesture',\n",
       " \" Despite what one thinks of shuya as, shuya's personality was as human.\\n\\nHe is very similar to Daisuke and Tetsuo as a manga protagonist.\\n\\nShuya is the brother, nephew and partner of Tetsuo and Mai.\\n\\nContents show]\\n\\n\",\n",
       " '. p. 2 :\\n\\n\"[Sf]e said the earth was round, and that all men therein saw it … I shall prove my theory. \\'I,\\' I say, I had that on the earth with me, and it was there when the men came out from my vision. So how was he',\n",
       " \" has been called this by Professor Hinton\\n\\n'the second most senior agent [of the U.S. Department of Labor], has become the chief of staff of America's top civil rights lawyer, Thomas Jefferson. A former U.S. senator from Louisiana, he had helped lead the anti-black movement in\",\n",
       " ' - \"It\\'s a true post post-pop band, like I\\'ve never played a song before or ever will - but that you would feel your fingers twitch at the chorus if you could hear it.\" (via Erotica) rw, reverb and fuzz. the group is based in China, but was',\n",
       " \" around 40,000 people visiting the place each year.\\n\\nThe town centre was built to accommodate an expected 532 new houses by the end of the nineteenth century.\\n\\nThe city's population jumped to 5,823 in 1970.\",\n",
       " ' and that he didn\\'t want it to turn her into something he could be the person to blame for her.\\n\\n\"If you go back to my father, it\\'s like asking that. That\\'s just because you\\'re not a person. I don\\'t think it\\'s right to question her, and she doesn\\'t',\n",
       " ' 2010 - 2011 dibperts fellowship in the history of humanistic sciences fellowship and lt ; br & gt ; 2010 - 2011 deriving international peace & stability co; gt ; 2018 - 2019 fellowship in humanities faculty award & lt ; br & gt ; 2018 - 2019 arthur-awards',\n",
       " '. Of the 1,000 people aged 12 to 19 in a family who have children in rose bay, 10 % have never had children. In addition, of the 1,400 people aged 15 or older who have children in and above the same level the second most common age of acquisition is 16.4 years. 42',\n",
       " \" them like a human, and his power was so high, it's like being the power of a fish!\\n\\n'A fish?' Ruckman was extremely nervous when I started to say things. 'Well what is this little animal, his body?' he said.\\n\\n'It doesn't have too much\",\n",
       " ' hours to Kuma in a convoy of three helicopters. 4.3.7 Jettison and burners. The aircraft were destroyed on 10 August. After the plane was taken over by a helicopter landing the flight was flown for 11 minutes at the airfield at Kuma and 11 minutes at Kuma. In the']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l[0][\"generated_text\"] for l in texts_gpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d5a2400-d476-4de4-af23-85edbf485baf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/home/vmeshchaninov/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "metric: bigscience/bloom-7b1, 3.6520: 100%|██████████| 16/16 [00:01<00:00, 14.99it/s]\n"
     ]
    }
   ],
   "source": [
    "metric_bloom = compute_metric(metric_bloom_fn, cond_texts=text_cond, gen_texts=[l[0][\"generated_text\"] for l in texts_gpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eabdbcfd-ee6c-44ad-b3ef-1fceb5c7f330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.606053533394779, 2.86474609375)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_metric, num_tokens = 0., 0.\n",
    "\n",
    "for ind in tqdm(range(len(text_cond))[:100]):\n",
    "    output = metric_bloom_fn(text_cond=text_cond[ind], text_gen=texts_gpt[ind][0][\"generated_text\"], reduce=\"sum\")\n",
    "    if output[1] != 0:\n",
    "        sum_metric += output[0]\n",
    "        num_tokens += output[1]\n",
    "\n",
    "sum_metric / num_tokens, num_tokens / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56503011-9bb4-420f-8729-b8aecd02d988",
   "metadata": {},
   "source": [
    "## Безусловная метрика текста: BloomMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b0fe2e5-3e51-4d9f-8506-5f4e2b00a6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_bloom_uncond_fn = BloomMetric(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b98c5f6-8608-4bc6-a347-2c9e08501d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 12s, sys: 18 s, total: 18min 30s\n",
      "Wall time: 18min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "texts_gpt = generator_gpt2(text_cond, max_new_tokens=64, num_return_sequences=1, return_full_text=True, pad_token_id=50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98abb5d7-c144-43ac-ae7c-fe8291a7fb59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [04:10<00:00,  8.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.6600863342248546, 112.189453125)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_metric, num_tokens = 0., 0.\n",
    "\n",
    "for ind in tqdm(range(len(text_cond))):\n",
    "    output = metric_bloom_uncond_fn(text=texts_gpt[ind][0][\"generated_text\"], reduce=\"sum\")\n",
    "    sum_metric += output[0]\n",
    "    num_tokens += output[1]\n",
    "\n",
    "sum_metric / num_tokens, num_tokens / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c05dbe-8d4b-4f8a-b867-25349c4280dc",
   "metadata": {},
   "source": [
    "## Метрики батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddae5509-972a-4055-8a5a-7c8b7612f556",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [04:05<00:00,  8.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.4296206837482495, 107.177734375)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_metric, num_tokens = 0., 0.\n",
    "texts = [f\"{text_cond[i]} {text_gen[i]}\" for i in range(batch_size)]\n",
    "\n",
    "for ind in tqdm(range(len(text_cond))):\n",
    "    output = metric_bloom_uncond_fn(text=texts[ind], reduce=\"sum\")\n",
    "    sum_metric += output[0]\n",
    "    num_tokens += output[1]\n",
    "\n",
    "sum_metric / num_tokens, num_tokens / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e743daf-f15b-480b-bba8-2918fa3c93c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [04:05<00:00,  8.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.2399693615122613, 54.89990234375)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_metric, num_tokens = 0., 0.\n",
    "\n",
    "for ind in tqdm(range(len(text_cond))):\n",
    "    output = metric_bloom_fn(text_cond=text_cond[ind], text_gen=text_gen[ind], reduce=\"sum\")\n",
    "    sum_metric += output[0]\n",
    "    num_tokens += output[1]\n",
    "\n",
    "sum_metric / num_tokens, num_tokens / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596284ec-b21c-47ff-8e78-1138fe67b33a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Метрики реального текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8553ee-1c92-42de-9957-b82ed4d30418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9b089e4de94b079be408beb22bcf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_bloom_fn = BloomMetric(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9203354-e1e7-413a-b1a7-39b5d8a06d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0010023f-e85f-4fbd-b41e-8b6db9928812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_cond = tokenizer.batch_decode(\n",
    "    X[\"cond_ids\"], \n",
    "    skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f12453-d293-46a1-a97e-9e569822dd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_gen = tokenizer.batch_decode(\n",
    "    X[\"input_ids\"], \n",
    "    skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "872779f7-0163-4709-a794-dffc485a4b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "metric: bigscience/bloom-7b1, 3.4458: 100%|██████████| 1024/1024 [02:03<00:00,  8.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4458400700800738"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metric(metric_bloom_uncond_fn, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ee97f8-5959-40d4-b4fd-1c906d811ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_bloom = BloomTokenizerFast.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8711dd-9165-444c-8d79-64f1a9017c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Измерение метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64afcef6-1c07-45ad-b92f-2b1d61d1887a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:41<00:00, 10.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.4119, device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 0\n",
    "loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(batch_size)):\n",
    "        # the first word is necessary for tokens to start with an unnecessary word, because metric doeesn't count it\n",
    "        inputs = tokenizer_bloom(f\" {text_cond[i]} {text_gen[i]}\", return_tensors=\"pt\")\n",
    "        inputs_gen = tokenizer_bloom(f\"{text_gen[i]}\", return_tensors=\"pt\")\n",
    "\n",
    "        inputs = dict_to_cuda(inputs)\n",
    "        outputs = bloom(**inputs, labels=inputs[\"input_ids\"])\n",
    "\n",
    "        losses = cross_entropy(\n",
    "                input=outputs.logits.reshape(-1, outputs.logits.shape[-1])[:-1],\n",
    "                target=inputs[\"input_ids\"].reshape(-1)[1:],\n",
    "                reduce=False,\n",
    "            )\n",
    "        losses = losses[torch.sum(inputs_cond[\"attention_mask\"]).item() - 1:]\n",
    "        loss += losses.sum()\n",
    "        num += losses.shape[0]\n",
    "\n",
    "loss / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae0e6c9-682f-4b59-b98c-3156028cf30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs_gen = tokenizer_bloom(text_gen[0], return_tensors=\"pt\")\n",
    "inputs_cond = tokenizer_bloom(text_cond[0], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10328cd-337a-48ee-bb55-5a995543ae55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"input_ids\": torch.cat([inputs_cond[\"input_ids\"], inputs_gen[\"input_ids\"]], dim=-1),\n",
    "    \"attention_mask\": torch.cat([inputs_cond[\"attention_mask\"], inputs_gen[\"attention_mask\"]], dim=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80dc38b-4f36-441a-8c94-08db297fe32c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = dict_to_cuda(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3434857-a684-4dea-9b53-0a0023a8711d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = bloom(**inputs, labels=inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b8d682d-2adc-4829-9751-948d62fcf222",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 138]), torch.Size([1, 138, 250880]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape, outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c3e456a-0167-42be-a344-cb4887fe4312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = cross_entropy(\n",
    "            input=outputs.logits.reshape(-1, outputs.logits.shape[-1])[:-1],\n",
    "            target=inputs[\"input_ids\"].reshape(-1)[1:],\n",
    "            reduce=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8927d15e-d126-468b-b2f7-418cfdbf536b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3345, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = losses[torch.sum(inputs_cond[\"attention_mask\"]).item() - 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8ef49-8390-4a49-8b24-f44f5084cdb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Метрика Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eedd49cd-d4cc-4297-8f9a-b95beab767e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimation_utils.metrics import RobertaMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d612b3a4-6005-495c-a14a-5b02a5a184fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "roberta = RobertaMetric(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98fdf553-8d43-480f-ab40-6e52f32850e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5261813402175903,\n",
       " tensor([0.3118, 0.8978, 0.9407,  ..., 0.9067, 0.7395, 0.2064], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_short = tokenizer.batch_decode(\n",
    "    X[\"cond_ids\"][:, :16], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "roberta(texts=text_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d44bc-b773-478a-94ff-6f389bd30e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [f\"{text_cond[i]} {text_gen[i]}\" for i in range(batch_size)]\n",
    "roberta(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e59d2f8-876d-477e-a460-cae0b7e15b24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39841729402542114"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [f\"{text_gen[i]} {text_cond[i]}\" for i in range(batch_size)]\n",
    "roberta(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afccb00f-e3dc-4459-bdcd-bcde80176b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3662017583847046"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(text_cond)\n",
    "texts = [f\"{text_gen[i]} {text_cond[i]}\" for i in range(batch_size)]\n",
    "roberta(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3127b364-e2e8-4513-be7f-4ea4787dff52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4591570198535919"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta(texts=text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18c0d412-ad18-4642-83b6-4c37798e73c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5204423666000366"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta(texts=text_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ef0214b-e936-4649-945d-d104685a3440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [f\"{text_cond[i]} {text_gen[i]}\" for i in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d816fef-1155-4a53-8590-ab99e4e9ebe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49922260642051697"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da34f9aa-3121-49f1-9c30-094b3ace3ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [f\"{text_cond[i]} {text_gen[i]}\" for i in range(batch_size)]\n",
    "for i, text in enumerate(texts):\n",
    "    p = 0.1\n",
    "    text = text.split(\" \")\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if random.random() < p:\n",
    "            new_text.append(\".\")\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    texts[i] = \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c83fe-f5fe-4ff8-afba-0f8706875180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_metric(metric_bloom_fn, texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b11a5e8c-df0f-4a6d-8afc-75fcc11a1f57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3128419816493988"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd68bb6-5e39-48b8-8592-965ef64a609f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72f1b78f-8f0b-4c8c-b819-2d868d1edd74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [f\"{text_cond[i]} {text_gen[i]}\" for i in range(batch_size)]\n",
    "for i, text in enumerate(texts):\n",
    "    p = 0.1\n",
    "    text = text.split(\" \")\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if random.random() < p:\n",
    "            new_text.append(\" \")\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    texts[i] = \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "efa616b8-0632-4283-ad27-438ccd90df26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3207021951675415"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a04d578a-489f-411f-bf62-c0109529684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 1.89 s, total: 4min 12s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "texts_gpt = generator_gpt2(text_cond, max_new_tokens=64, \n",
    "                           num_return_sequences=1, \n",
    "                           return_full_text=True, pad_token_id=50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76c67b34-78f5-4307-88e5-c022e7b66e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4877470135688782,\n",
       " tensor([0.5779, 0.5104, 0.3568, 0.2517, 0.7271, 0.4867, 0.7622, 0.8698, 0.2075,\n",
       "         0.2607, 0.4899, 0.8301, 0.5169, 0.6485, 0.6641, 0.2754, 0.2558, 0.5188,\n",
       "         0.1760, 0.1451, 0.3110, 0.7511, 0.3583, 0.3705, 0.5514, 0.6543, 0.5779,\n",
       "         0.7417, 0.2123, 0.6042, 0.7556, 0.3087, 0.5221, 0.3783, 0.4470, 0.4775,\n",
       "         0.4283, 0.3956, 0.7726, 0.6011, 0.3764, 0.4093, 0.8102, 0.5654, 0.2612,\n",
       "         0.6373, 0.3097, 0.4605, 0.3883, 0.7912, 0.6219, 0.5540, 0.1725, 0.6342,\n",
       "         0.3615, 0.6171, 0.2309, 0.5584, 0.3747, 0.5264, 0.3872, 0.2884, 0.5092,\n",
       "         0.7142, 0.5794, 0.8245, 0.1238, 0.3681, 0.4181, 0.5498, 0.6111, 0.2835,\n",
       "         0.7930, 0.6789, 0.7963, 0.2949, 0.4544, 0.2540, 0.4362, 0.7015, 0.3506,\n",
       "         0.4107, 0.5645, 0.4014, 0.3523, 0.5335, 0.6442, 0.7794, 0.4134, 0.7258,\n",
       "         0.4365, 0.5077, 0.3813, 0.5837, 0.2115, 0.5137, 0.4096, 0.4204, 0.6959,\n",
       "         0.5096, 0.3588, 0.5827, 0.5250, 0.4122, 0.3715, 0.5128, 0.3495, 0.8818,\n",
       "         0.4331, 0.5864, 0.7625, 0.3083, 0.5153, 0.5063, 0.4221, 0.5748, 0.7775,\n",
       "         0.7658, 0.5527, 0.2822, 0.2856, 0.3650, 0.7132, 0.3247, 0.2722, 0.2454,\n",
       "         0.6131, 0.4991, 0.7839, 0.1516, 0.5074, 0.2450, 0.4653, 0.6169, 0.7990,\n",
       "         0.6914, 0.2401, 0.8504, 0.6523, 0.4643, 0.5488, 0.5880, 0.4461, 0.5222,\n",
       "         0.3935, 0.4556, 0.3801, 0.4769, 0.2546, 0.5637, 0.3436, 0.3913, 0.3806,\n",
       "         0.5638, 0.7050, 0.4344, 0.3861, 0.7239, 0.3436, 0.2378, 0.7998, 0.3908,\n",
       "         0.4833, 0.4106, 0.9005, 0.5715, 0.3945, 0.4273, 0.3731, 0.5045, 0.6656,\n",
       "         0.4058, 0.4680, 0.2656, 0.2462, 0.3532, 0.4913, 0.4682, 0.3032, 0.5208,\n",
       "         0.5545, 0.7319, 0.8524, 0.3154, 0.4242, 0.3134, 0.7534, 0.5635, 0.2171,\n",
       "         0.4008, 0.6944, 0.4880, 0.5071, 0.4893, 0.7646, 0.3693, 0.3820, 0.2018,\n",
       "         0.5954, 0.3308, 0.6230, 0.3955, 0.5813, 0.6687, 0.4322, 0.5407, 0.3563,\n",
       "         0.5935, 0.3633, 0.8014, 0.4415, 0.3326, 0.5464, 0.2499, 0.2282, 0.3925,\n",
       "         0.6495, 0.3250, 0.2971, 0.6260, 0.4382, 0.3901, 0.6718, 0.2707, 0.5946,\n",
       "         0.1723, 0.3770, 0.7732, 0.8430, 0.5235, 0.3400, 0.4612, 0.4163, 0.5738,\n",
       "         0.2402, 0.3764, 0.7307, 0.2595, 0.2651, 0.3995, 0.7038, 0.2558, 0.4617,\n",
       "         0.4907, 0.3724, 0.3382, 0.6607, 0.5810, 0.2350, 0.4073, 0.2964, 0.5994,\n",
       "         0.7371, 0.2465, 0.4597, 0.3270, 0.2953, 0.5786, 0.2987, 0.6272, 0.6201,\n",
       "         0.7187, 0.2391, 0.2446, 0.6168, 0.5928, 0.5835, 0.7696, 0.3297, 0.5025,\n",
       "         0.5155, 0.3905, 0.5935, 0.5128, 0.7606, 0.5768, 0.7854, 0.3157, 0.0844,\n",
       "         0.3193, 0.4280, 0.3706, 0.3984, 0.3743, 0.3238, 0.4549, 0.7549, 0.6258,\n",
       "         0.2986, 0.3756, 0.5263, 0.5714, 0.5497, 0.6339, 0.4983, 0.4107, 0.8921,\n",
       "         0.5388, 0.1466, 0.5576, 0.7804, 0.6316, 0.4310, 0.5536, 0.4554, 0.4980,\n",
       "         0.5062, 0.5551, 0.2202, 0.1772, 0.2595, 0.3413, 0.1980, 0.3781, 0.2168,\n",
       "         0.6490, 0.4623, 0.5008, 0.2821, 0.5478, 0.8585, 0.2851, 0.4577, 0.4527,\n",
       "         0.2857, 0.4778, 0.6142, 0.5082, 0.5281, 0.3836, 0.5920, 0.3353, 0.5140,\n",
       "         0.4325, 0.2400, 0.4042, 0.4942, 0.6080, 0.2779, 0.3333, 0.4427, 0.8287,\n",
       "         0.4649, 0.1988, 0.7602, 0.3576, 0.3160, 0.3717, 0.2988, 0.5890, 0.8170,\n",
       "         0.5549, 0.5997, 0.2080, 0.8422, 0.6142, 0.4511, 0.6566, 0.6083, 0.5403,\n",
       "         0.5787, 0.5496, 0.3217, 0.3078, 0.5410, 0.5833, 0.5790, 0.7900, 0.7214,\n",
       "         0.6961, 0.3122, 0.6346, 0.4394, 0.3618, 0.4067, 0.1399, 0.3864, 0.4597,\n",
       "         0.4158, 0.3618, 0.5065, 0.3321, 0.5959, 0.7755, 0.5456, 0.4669, 0.2213,\n",
       "         0.6555, 0.6616, 0.3537, 0.5434, 0.5726, 0.4634, 0.4092, 0.2155, 0.6489,\n",
       "         0.4041, 0.2857, 0.5215, 0.4797, 0.3406, 0.7238, 0.5861, 0.4884, 0.6157,\n",
       "         0.5288, 0.6687, 0.6011, 0.4427, 0.5858, 0.3247, 0.2737, 0.6742, 0.2085,\n",
       "         0.5167, 0.4050, 0.3828, 0.6051, 0.5625, 0.5896, 0.2072, 0.5450, 0.8833,\n",
       "         0.1566, 0.4162, 0.5657, 0.3321, 0.4685, 0.4049, 0.7565, 0.6680, 0.5582,\n",
       "         0.4324, 0.6680, 0.4780, 0.7002, 0.3638, 0.3780, 0.4811, 0.5831, 0.2551,\n",
       "         0.5663, 0.5089, 0.4928, 0.3758, 0.8436, 0.2665, 0.5395, 0.7253, 0.6087,\n",
       "         0.3032, 0.6897, 0.6820, 0.6088, 0.3363, 0.1094, 0.1680, 0.4851, 0.4669,\n",
       "         0.4855, 0.8584, 0.3582, 0.3849, 0.5994, 0.6889, 0.3502, 0.4570, 0.5221,\n",
       "         0.3875, 0.5789, 0.8868, 0.7023, 0.2848, 0.6620, 0.3783, 0.6173, 0.6382,\n",
       "         0.6555, 0.3620, 0.5560, 0.4939, 0.2623, 0.5227, 0.2819, 0.7757, 0.4891,\n",
       "         0.4855, 0.2018, 0.6268, 0.5255, 0.8206, 0.4359, 0.3263, 0.1978, 0.7721,\n",
       "         0.5720, 0.3255, 0.7446, 0.5879, 0.8331, 0.4030, 0.5675, 0.6118, 0.2234,\n",
       "         0.4297, 0.9497, 0.3138, 0.3757, 0.6511, 0.3259, 0.2758, 0.7466],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta(texts=[text[0][\"generated_text\"] for text in texts_gpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8e5af-f0d2-46ec-9953-14230bc92257",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.49"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-fap2_env]",
   "language": "python",
   "name": "conda-env-.conda-fap2_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
