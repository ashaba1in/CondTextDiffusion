{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f55db5a-4896-4cb9-9088-bc45880d4f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef319fcd-c8a9-483e-a363-b0a56545f98e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44de78fa-0c46-4bab-9e4c-dd8ba614191f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusion_holder import DiffusionRunner\n",
    "from transformers import BertConfig, BertTokenizerFast\n",
    "\n",
    "from diffusion_holder import DiffusionRunner\n",
    "from utils.util import set_seed, dict_to_cuda\n",
    "from estimation_utils.util import estimate_model, reduce_metrics, gather_texts\n",
    "import diffusion_utils.schedulers as schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3bdea-fbef-49f5-81ef-ed1c36aeacca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4a11a7-5380-463d-a6c3-dd604b23a544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    training = config.training = ml_collections.ConfigDict()\n",
    "    training.training_iters = 500_000\n",
    "    training.training_iters = training.training_iters\n",
    "    training.checkpoint_freq = 50_000\n",
    "    training.eval_freq = 5_000\n",
    "    training.batch_size = 512  # * 8\n",
    "\n",
    "    training.ode_sampling = False\n",
    "    training.checkpoints_folder = '../checkpoints/'\n",
    "    config.checkpoints_prefix = ''\n",
    "\n",
    "    loss = config.loss = ml_collections.ConfigDict()\n",
    "    loss.ce_coef = 0.\n",
    "\n",
    "    refresh = config.refresh = ml_collections.ConfigDict()\n",
    "    refresh.true = False\n",
    "    refresh.prefix = \"./checkpoints/wikipedia--t5-bert-self_cond_500000_.pth\"\n",
    "    refresh.wand_id = \"g5fb4af3\"\n",
    "\n",
    "    validation = config.validation = ml_collections.ConfigDict()\n",
    "    validation.batch_size = 4\n",
    "    validation.validation_iters = int(10_000 / validation.batch_size)\n",
    "    validation.num_gen_texts = 8192\n",
    "    validation.p_uncond = 0.\n",
    "\n",
    "    dynamic = config.dynamic = ml_collections.ConfigDict()\n",
    "    dynamic.solver = 'euler'\n",
    "    dynamic.scheduler = \"sd\"\n",
    "    dynamic.N = 200\n",
    "    dynamic.beta_min = 0.1\n",
    "    dynamic.beta_max = 20\n",
    "    dynamic.ode_sampling = False\n",
    "    dynamic.coef_d = 10\n",
    "\n",
    "    model = config.model = ml_collections.ConfigDict()\n",
    "    model.ema_rate = 0.9999\n",
    "    model.enc_type = \"base\"\n",
    "    model.embeddings_type = \"embeddings\"\n",
    "    model.dif_enc_type = \"base\"\n",
    "    model.downstream_task = \"\"  # \"qqp\"\n",
    "    model.dataset = \"wikipedia\"  # \"glue\"\n",
    "    model.prediction = \"x_0\"\n",
    "    model.loss = \"L_x_0\"\n",
    "    model.decoder_path = \"decoder-wikipedia-128.pth\"\n",
    "\n",
    "    data = config.data = ml_collections.ConfigDict()\n",
    "    data.max_sequence_len = 64\n",
    "    data.pos_begin = 0.0\n",
    "    data.pos_end = 0.67\n",
    "    data.enc_bert_mean = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-bert_base-wiki-mean.pt\"\n",
    "    data.enc_bert_std = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-bert_base-wiki-std.pt\"\n",
    "\n",
    "    data.enc_t5_mean = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-t5-wiki-mean.pth\"\n",
    "    data.enc_t5_std = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-t5-wiki-std.pth\"\n",
    "\n",
    "    config.finetuning = False\n",
    "    config.seed = 0\n",
    "    config.ddp = False\n",
    "    config.bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "    config.use_self_cond = True\n",
    "    config.project_name = \"test\" #\"dtg-exps-1.0\"\n",
    "    config.timesteps = \"linear\"\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2216bf3b-a34a-4a20-90cd-2469a9cc401e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/.conda/envs/fap2_env/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at t5-base were not used when initializing T5EncoderModel: ['decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.final_layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5EncoderModel were not initialized from the model checkpoint at t5-base and are newly initialized: ['enc_normalizer.enc_mean', 'enc_normalizer.enc_std']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoderModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertEncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertEncoderModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['enc_normalizer.enc_std', 'enc_normalizer.enc_mean']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc0548f70bf4529a164c31c5f6d2699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset tokenization (num_proc=30):   0%|          | 0/38661 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = create_config()\n",
    "config.checkpoints_prefix = \"wikipedia--t5-bert-self_cond_last_\"\n",
    "\n",
    "diffusion = DiffusionRunner(config, latent_mode=config.model.embeddings_type, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6ef56-f084-483d-b117-6000602cbfeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/.conda/envs/fap2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "diffusion.set_valid_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5289794e-a461-47af-8fa5-61b22a613194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = iter(diffusion.valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94551c67-cd3c-4954-a2f6-3b4452951e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = next(loader)\n",
    "X = dict_to_cuda(X)\n",
    "\n",
    "with torch.no_grad():\n",
    "    clean_X = diffusion.encoder_gen(**{\"input_ids\": X[\"input_ids\"], \"attention_mask\": X[\"input_mask\"]})\n",
    "    cond_X = diffusion.encoder_cond(**{\"input_ids\": X[\"cond_ids\"], \"attention_mask\": X[\"cond_mask\"]})\n",
    "    \n",
    "cond_mask = X[\"cond_mask\"]\n",
    "attention_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20bf8ae1-01a1-4075-8879-ff2965f3c761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps_t = 1. / diffusion.dynamic.N\n",
    "timesteps = torch.linspace(diffusion.dynamic.T, eps_t, diffusion.dynamic.N, device=diffusion.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bebcd4dd-541a-4843-97cb-5e7eb12a18ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_list = []\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50e7b8a0-2c39-4780-b6f3-35bb43ea96a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 41.33it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch_size = config.validation.batch_size\n",
    "    x = diffusion.dynamic.prior_sampling(clean_X.shape).to(diffusion.device)\n",
    "\n",
    "    for idx in tqdm(range(diffusion.dynamic.N)):\n",
    "        t = timesteps[idx]\n",
    "        next_t = timesteps[idx + 1] if idx < diffusion.dynamic.N - 1 else eps_t\n",
    "\n",
    "        input_t = t * torch.ones(batch_size, device=diffusion.device)\n",
    "        next_input_t = next_t * torch.ones(batch_size, device=diffusion.device)\n",
    "\n",
    "        output = diffusion.diff_eq_solver.step(\n",
    "            x_t=x, t=input_t, next_t=next_input_t,\n",
    "            cond=cond_X,\n",
    "            cond_mask=cond_mask,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        x, x_mean = output[\"x\"], output[\"x_mean\"]\n",
    "        x_list.append(output[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dc01899-20f8-46ef-8207-16945d972770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def make_gif_from_list_of_tensors(x_list):\n",
    "    images = []\n",
    "    for idx in range(diffusion.dynamic.N):\n",
    "        embeds = x_list[idx][0].cpu().numpy()\n",
    "        image = np.array(embeds[:, :128])\n",
    "        image -= image.min()\n",
    "        image /= image.max()\n",
    "\n",
    "        image = Image.fromarray(np.uint8(image * 255))\n",
    "        image = image.resize((128 * 4, 32 * 4), resample=Image.NEAREST)\n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "    images[0].save(\n",
    "                'animation-x_t.gif',\n",
    "                save_all=True,\n",
    "                append_images=images[1:], # append rest of the images\n",
    "                duration=100, # in milliseconds\n",
    "                loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75a721de-daed-4b3d-9ca7-0388b97df27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_gif_from_list_of_tensors(x_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e47d8-62e8-4780-b59e-28478cffa8e1",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b7d11f-469c-4d6e-8c8b-6998134cc38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_list = []\n",
    "token_list = []\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9697f844-7be1-46b7-9362-941ca2179510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 43.28it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch_size = config.validation.batch_size\n",
    "    x = diffusion.dynamic.prior_sampling(clean_X.shape).to(diffusion.device)\n",
    "\n",
    "    x_0_self_cond = torch.zeros_like(x, dtype=x.dtype)\n",
    "    \n",
    "    for idx in tqdm(range(diffusion.dynamic.N)):\n",
    "        t = timesteps[idx]\n",
    "        next_t = timesteps[idx + 1] if idx < diffusion.dynamic.N - 1 else eps_t\n",
    "\n",
    "        input_t = t * torch.ones(batch_size, device=diffusion.device)\n",
    "        next_input_t = next_t * torch.ones(batch_size, device=diffusion.device)\n",
    "\n",
    "        \n",
    "        \n",
    "        output = diffusion.diff_eq_solver.step(\n",
    "            x_t=x, t=input_t, next_t=next_input_t,\n",
    "            cond=cond_X,\n",
    "            cond_mask=cond_mask,\n",
    "            attention_mask=attention_mask,\n",
    "            x_0_self_cond=x_0_self_cond\n",
    "        )\n",
    "\n",
    "        x, x_mean = output[\"x\"], output[\"x_mean\"]\n",
    "        x_0_self_cond = output[\"x_0\"]\n",
    "        \n",
    "        tokens = diffusion.pred_logits(output[\"x_0\"]).argmax(dim=-1)\n",
    "        token_list.append(tokens[0].cpu().numpy())\n",
    "        \n",
    "        text = diffusion.tokenizer_gen.batch_decode(tokens, skip_special_tokens=True)\n",
    "        text_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00e34752-3372-4fc7-b953-781bcfe55712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['april 2005, the vazm series received new interior lights and anive instrument. as was usual with high - volume sedans, the longer part of the backed was replaced with white flesh. in june 2005, the vezm, like with many other thhrdict lineates, received several changes.',\n",
       " 'removal of hall bands bassist steve lines, who would later become the guitarist of the british rock band the blacksd.',\n",
       " 'member of the parliament of ireland ( parliament ) at the 1920 general election for the constituency of lake crm. he was a member of the for north dublin at the 1929 general election, 1887 general election and 1889 general election. in 1886 he was elected as an pp candidate. he was a',\n",
       " \"the event featured major changes to the driving : each team required 6 minutes to obtain victory if temperatures had changed. in the final race at mata de gibraltar, the teams of joseph and mcgan required 2 minutes each, while joseph and mcgathi were able to race on any of three criterrs '\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "030b22e7-a61d-4030-abcf-2e25a6faaae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "n_first_tokens = 31\n",
    "\n",
    "tokens = [t[n].replace(\",\", \" ,\").replace(\".\", \" .\").split()[:n_first_tokens] for t in text_list[::-1][::20][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a85bd5ce-a266-4eb0-ae07-0238e366fb20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "enumerate() missing required argument 'iterable' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m n_first_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      4\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [t[n]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m .\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()[:n_first_tokens] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text_list[::\u001b[38;5;241m10\u001b[39m]]\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      7\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m11\u001b[39m\n\u001b[1;32m      8\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(i)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: enumerate() missing required argument 'iterable' (pos 1)"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(tokens):\n",
    "    n = 11\n",
    "    s = f\"{i}{' ' * (2 - len(str(i)))} \"\n",
    "    for c in t:\n",
    "        s += f\"{c}{' ' * (n - len(str(c)))}\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24a1a287-f9f5-4c18-8b28-6bf7e72b2f14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91           0.81           0.70           0.61           0.50           0.41           0.31           0.20           0.10           0.00           \n",
      "the            the            the            the            the            the            the            the            the            the            \n",
      "-              -              drivers        chassis        results        race           race           race           event          event          \n",
      "-              -              .              for            were           saw            saw            saw            featured       featured       \n",
      "-              -              chassis        bar            significantly  several        several        several        major          major          \n",
      "-              -              ,              changes        changes        changes        changes        changes        changes        changes        \n",
      "-              -              ,              to             to             to             to             to             to             to             \n",
      "-              -              that           the            the            the            the            the            the            the            \n",
      "-              -              that           championship   race           chassis        chassis        chassis        chassis        driving        \n",
      "-              -              the            .              :              :              :              :              :              :              \n",
      "-              the            team           each           each           each           each           each           each           each           \n",
      "-              -              and            team           team           team           team           team           team           team           \n",
      "-              -              -              had            required       required       required       required       required       required       \n",
      "-              -              -              two            five           five           six            6              6              6              \n",
      "-              -              -              minutes        minutes        minutes        minutes        minutes        minutes        minutes        \n",
      "-              -              -              to             to             to             to             to             to             to             \n",
      "-              -              and            -              earn           establish      establish      earn           acquire        obtain         \n",
      "-              -              ,              start          victory        victory        victory        victory        victory        victory        \n",
      "-              and            -              if             if             if             if             if             if             if             \n",
      "-              -              the            they           engineering    engineering    conditions     temperatures   temperatures   temperatures   \n",
      "-              -              -              -              issues         issues         had            had            had            had            \n",
      "-              -              the            .              occurred       occurred       changed        changed        changed        changed        \n",
      "-              -              -              .              .              .              .              .              .              .              \n",
      "-              -              -'-            the            in             in             in             in             in             in             \n",
      "-              -              the            previous       the            the            the            the            the            the            \n",
      "-              -              -              the            final          final          final          last           final          final          \n",
      "-              -              the            race           race           race           race           race           race           race           \n",
      "the            -              -              at             at             at             at             at             at             at             \n",
      "-              -              -              matancallo     sanncaa        monte          ciudad         santiago       santiago       mata           \n",
      "-              -              -              ,              ,              desta          de             de             de             de             \n",
      "-              the            and            the            the            ,              monte          mata           mata           gibraltar      \n",
      "-              -              -'-            teams          teams          the            ,              ,              ,              ,              \n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "\n",
    "s = \"\"\n",
    "steps = timesteps.tolist()\n",
    "for step in steps[::-1][::20][::-1]:\n",
    "    c = f\"{step:0.2f}\"\n",
    "    s += f\"{c}{' ' * (n - len(str(c)))}\"\n",
    "print(s)\n",
    "\n",
    "for ind_token in range(len(tokens[0])):\n",
    "    s = \"\"\n",
    "    for step_tokens in tokens:\n",
    "        c = step_tokens[ind_token]\n",
    "        s += f\"{c}{' ' * (n - len(str(c)))}\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c20c844-7830-42a1-a6a5-04d2d8930b37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the vibe was also made in tandem with a toyota model, the toyota matrix, at the nummi plant. the prizm along with its geo siblings suffered severe sales loss when the brand denomination changed from geo to chevrolet in',\n",
       " \"0 may also refer to : one of king's greatest influences was the\",\n",
       " 'cornelius bolton ( – 16 september 1779 ) was an irish landowner and politician. biography. he was made a',\n",
       " \"in an effort to create a more competitive field in organizers announced a series of changes to the championship. the most significant was that from the teams have had to run on pirelli control or'spec'tyres. the standard of dunlop and michelin that most of\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion.tokenizer_cond.batch_decode(X[\"cond_ids\"], skip_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "401c053b-4a3d-456c-8688-61a650f42224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  101   1011  1998  1998  1998  1998  1998  1998  1998  1011  1998  1998  1011  1998  1998  1011  \n",
      "1  101   1011  1998  1998  1998  1998  1998  1998  1998  1998  1998  1998  1998  1998  1998  1011  \n",
      "2  101   1011  1998  1998  1998  1998  1998  1998  1998  1998  1998  1011  1011  1998  1998  1998  \n",
      "3  101   1011  1998  1998  1011  1998  1998  1998  1998  1998  1998  1011  1011  1998  1998  1998  \n",
      "4  101   1005  1998  1998  1012  1998  1998  1998  1998  1998  1998  1996  1996  1998  1998  1998  \n",
      "5  101   1998  1998  1998  1011  1011  1998  1998  1998  1998  1998  1998  1998  1998  1998  1998  \n",
      "6  101   1998  1998  2000  1996  1998  12241 1011  1998  1998  1998  1998  1998  1998  1998  1998  \n",
      "7  101   1011  1998  2000  1037  1011  12241 14399 1998  1998  2004  1998  1996  1998  1011  14399 \n",
      "8  101   1011  1011  1997  1037  8991  15134 15134 1998  2001  1998  1998  2000  1998  1011  2835  \n",
      "9  101   2918  10515 2007  1037  1018  1011  1019  1011  2944  1998  1998  2000  1037  1011  1011  \n",
      "10 101   2918  2944  2007  1037  1018  1011  1019  1011  17290 15134 1010  2009  2001  2003  1011  \n",
      "11 101   2918  2944  2007  1037  2176  1011  1997  1011  2835  19521 1010  1998  2009  2003  2000  \n",
      "12 101   2918  2944  2007  1037  1018  1011  1019  1011  3715  19521 1010  2061  2009  2003  2025  \n",
      "13 101   2918  10515 2007  1037  1018  1011  1016  4373  3194  5209  1010  2061  2009  2003  2025  \n",
      "14 101   2918  2722  2007  1037  8991  1011  1016  1011  8991  5209  1010  2061  2009  2003  2025  \n",
      "15 101   9233  10515 2007  1037  1018  1011  2192  8991  8991  4275  1010  2061  2009  2003  2428  \n",
      "16 101   2944  2944  2007  1037  1018  1011  2835  4373  8991  5209  1010  1998  2009  2003  2941  \n",
      "17 101   2085  6055  2007  1037  1018  1011  19978 8991  9324  19978 1010  1998  2009  2003  2074  \n",
      "18 101   2036  6055  2007  1037  1018  1011  2835  8991  9324  19521 1010  1998  2009  2003  2941  \n",
      "19 101   3262  6055  2007  1037  1018  1011  19978 4373  21724 3194  1010  1998  2009  2003  5525  \n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(token_list[::10]):\n",
    "    n = 6\n",
    "    s = f\"{i}{' ' * (2 - len(str(i)))} \"\n",
    "    for c in t:\n",
    "        s += f\"{c}{' ' * (n - len(str(c)))}\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34e011-a406-401d-8ec6-0ca095ff70be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-fap2_env]",
   "language": "python",
   "name": "conda-env-.conda-fap2_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
