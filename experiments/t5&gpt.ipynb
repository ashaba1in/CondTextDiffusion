{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1707898a-0d8a-4f04-abd4-0dfdd2fcb407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04692cfe-a617-4a62-b36f-6de76a56af40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "from transformers import AutoTokenizer, T5Model, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711090b-1f2c-437a-a898-e0c2195ebbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6568d4c-dbb6-4319-838c-171508728b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b484a-f822-4f89-8d5e-26ae0da5e204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210535c-f207-496d-9725-9ae8c3a57481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2291f-c2de-43a4-83d0-e02778a2ceec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e7e8ade-2f08-4528-9f4d-955b0b972d02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df441994fb04f359cb7c02e840c099a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2794bf14c54f06b5a6d81e37b8679f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t5 = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0eb1e67-1903-4dfb-8d71-3c5cb4e581c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38b7f25325843b49fbbd387d29e2e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7878ca00e24875a4edf6051e9af2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/anaconda3/envs/env/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663a4d90-6ac8-4409-a8a6-4433c7914fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_cond = \"Unlike ordinary beam search, constrained beam search allows us to exert control over the \" \\\n",
    "            \"output of text generation. This is useful because we sometimes \" \\\n",
    "            \"know exactly what we want inside the output. For example, in a Neural Machine Translation task\"\n",
    "        \n",
    "text_uncond = \"we might know which words must be included in the final translation with a dictionary lookup. \" \\\n",
    "              \"Sometimes, generation outputs that are almost equally possible to a language model might not be equally \" \\\n",
    "              \"desirable for the end-user due to the particular context. Both of these situations could be solved by \" \\\n",
    "              \"allowing the users to tell the model which words must be included in the end output.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cef78601-d6a9-426b-8d65-b154c6af1f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(text_cond, return_tensors=\"pt\").input_ids\n",
    "labels = tokenizer(text_uncond, return_tensors=\"pt\").input_ids\n",
    "labels_s = t5._shift_right(labels)\n",
    "\n",
    "outputs = t5(input_ids=input_ids, decoder_input_ids=labels_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940fbba2-2852-466d-91eb-9700be8506a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6221, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(outputs.logits.reshape(-1, 32128), labels.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "232a0bb5-bee2-4155-8ee9-271ce43acf12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we might know which words must be included in the final translation with a dictionary lookup. Sometimes, generation outputs that are almost equally possible to a language model might not be equally desirable for the end-user due to the particular context. Both of these situations could be solved by allowing the users to tell the model which words must be included in the end output.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(labels_s, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4cea97-5c3f-4f56-8abb-691a698cc1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['want want exactly words we be translated in the output output. a particular.up., we of is are are not identical important are producea given are are be be the useful. different user useruser. to the large constraints. In methods these cases are be solved by cona us user to specify the system what words to be included. the output-.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs.logits.argmax(dim=-1), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1791e09a-292c-4a70-b914-4c27451eeeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: 62,     pr_ind: -1     proposed: [32099     3     6     5     1     7    18 32086    11 32092]\n",
      "true: 429,    pr_ind: 1      proposed: [241 429  54 214 164 174 557 133  43 169]\n",
      "true: 214,    pr_ind: 1      proposed: [  241   214   174 11610   169    43    36  1672  6634  2204]\n",
      "true: 84,     pr_ind: 6      proposed: [ 1776   125    24 11185     8   149    84   131     3   213]\n",
      "true: 1234,   pr_ind: 0      proposed: [ 1234  7142 16513  1499  1448   294  3785     3  1467  1612]\n",
      "true: 398,    pr_ind: -1     proposed: [  62   12   33  225   42   16   11   56    8 1776]\n",
      "true: 36,     pr_ind: 0      proposed: [  36 2385 3480  281   43  369 1588 4093 2367 1130]\n",
      "true: 1285,   pr_ind: 1      proposed: [15459  1285     3   261  6126  3911 21527  2546    16 23734]\n",
      "true: 16,     pr_ind: 0      proposed: [  16    5 1096   11  441   42  139   12    6   21]\n",
      "true: 8,      pr_ind: 0      proposed: [   8    3 3911   46   69  284 1499 3785  125 7314]\n",
      "true: 804,    pr_ind: 4      proposed: [ 3911  3785  1499  6126   804  7314     3   741  1448 15459]\n",
      "true: 7314,   pr_ind: 4      proposed: [3911 1499  741  556 7314 3785 6126 1448    3  772]\n",
      "true: 28,     pr_ind: -1     proposed: [   5 3911   13 1499    6  741  556    7   11   42]\n",
      "true: 3,      pr_ind: 0      proposed: [   3    8  975   69 1193  128  150   48   46 1090]\n",
      "true: 9,      pr_ind: 0      proposed: [    9    29 24703     4 17235 10643  6858 23313 30949     2]\n",
      "true: 24297,  pr_ind: -1     proposed: [1090  787  824  806  975  554  712 1499    3  356]\n",
      "true: 320,    pr_ind: -1     proposed: [   5   13    6   42   11 3785   24 1451   38   18]\n",
      "true: 413,    pr_ind: 0      proposed: [413  18  95   5   9  11  21  44   6   3]\n",
      "true: 5,      pr_ind: 0      proposed: [   5 1681   42    6   11 1451  953   21   16   12]\n",
      "true: 3921,   pr_ind: -1     proposed: [32095    86   100  1193   947    37     3   101   611 20114]\n",
      "true: 6,      pr_ind: 0      proposed: [  6  62  48   8  34  69 975 175 125  16]\n",
      "true: 3381,   pr_ind: -1     proposed: [ 62  48 983   8  34  69 125 713  16 175]\n",
      "true: 3911,   pr_ind: 7      proposed: [  13 4145   19   54 2491  772   11 3911  164 2311]\n",
      "true: 7,      pr_ind: 1      proposed: [  19    7   54   13  164 2579  225   65  398   56]\n",
      "true: 24,     pr_ind: -1     proposed: [  33   54   13   43  174  164  398 3480   45  225]\n",
      "true: 33,     pr_ind: 0      proposed: [  33   62 3480   43   54  103  560 1588 1457  174]\n",
      "true: 966,    pr_ind: -1     proposed: [  59 6126  975    3  396 3911  182 2546   72  315]\n",
      "true: 7509,   pr_ind: -1     proposed: [12022  1776   373    16  4586    73     8  1551  4585     3]\n",
      "true: 487,    pr_ind: -1     proposed: [  359   508  1561     3  1934 11152   307 24839  2193   975]\n",
      "true: 12,     pr_ind: 2      proposed: [ 33  54  12 164   5  21  16   6  42  56]\n",
      "true: 3,      pr_ind: -1     proposed: [ 1759  3806   610  9689    36  3442  5819  2174  1984 23307]\n",
      "true: 9,      pr_ind: 0      proposed: [    9    35 15222    60    15  4610 28209    32 25486     7]\n",
      "true: 1612,   pr_ind: -1     proposed: [ 787 1499  936 2491 1139 1090  356  806  712 1437]\n",
      "true: 825,    pr_ind: 4      proposed: [  33   54  114   19  825  224    6 2491   42   43]\n",
      "true: 429,    pr_ind: 4      proposed: [ 33  54 164   5 429  43   6  56  42  11]\n",
      "true: 59,     pr_ind: 1      proposed: [  36   59   43 3480  320   92 6339 1759  370  560]\n",
      "true: 36,     pr_ind: 0      proposed: [   36  1588   942    43 11132  3480  1400   237   373  1759]\n",
      "true: 7509,   pr_ind: -1     proposed: [    8   631  6684   487     3    38   125 23750  3255   347]\n",
      "true: 16441,  pr_ind: -1     proposed: [1934 4034  487   38 2024  207 3982 1231 2918 3255]\n",
      "true: 21,     pr_ind: 2      proposed: [  5  12  21   6  16  38  42  11 250   3]\n",
      "true: 8,      pr_ind: 2      proposed: [ 315    3    8  284   69  128 1499  178   66  936]\n",
      "true: 414,    pr_ind: -1     proposed: [1139 2387 2491 3785 1612  337 1437 3911 1499 7314]\n",
      "true: 18,     pr_ind: 1      proposed: [ 1139    18  1105  1288   741  2387 10041   556   917  5471]\n",
      "true: 10041,  pr_ind: 0      proposed: [10041 15892 26693 25697  8056 12251  1074  2700   235 24315]\n",
      "true: 788,    pr_ind: -1     proposed: [ 5  7  6 42 11 38 41 12  3 68]\n",
      "true: 12,     pr_ind: 0      proposed: [ 12   8 165  70   3  16   6 128   5 396]\n",
      "true: 8,      pr_ind: 0      proposed: [    8    70   315     3  1612 17765   165  2136 27632   796]\n",
      "true: 1090,   pr_ind: -1     proposed: [  508   306  2136     3  1643 11641 17765   315  1612 10005]\n",
      "true: 2625,   pr_ind: -1     proposed: [17765  3785  1612   753   485  1451 27632  1809     3  3911]\n",
      "true: 5,      pr_ind: 0      proposed: [   5   13   16    7   62   24   79   34   11 1096]\n",
      "true: 2867,   pr_ind: -1     proposed: [  86  100 1193    3  947  242    1   37  101  304]\n",
      "true: 13,     pr_ind: 2      proposed: [ 2254   975    13  6315 11638  2097   175  1308    33     8]\n",
      "true: 175,    pr_ind: 0      proposed: [175   8 135  69 273  48 178  84 224  82]\n",
      "true: 4147,   pr_ind: 2      proposed: [ 1488 13911  4147  4062    33  2081  6315  1124  4145  1564]\n",
      "true: 228,    pr_ind: 8      proposed: [  33   54 1457   43 4093 7931  164 3223  228  133]\n",
      "true: 36,     pr_ind: 0      proposed: [  36 4093  991 7931 1837 1153 1581  741   43 6149]\n",
      "true: 16384,  pr_ind: 0      proposed: [16384  8705 10298     3  5153  1153  3028  1736 13803  1702]\n",
      "true: 57,     pr_ind: 0      proposed: [  57   28  338   16  190 1009    5 1153  270   21]\n",
      "true: 3,      pr_ind: 2      proposed: [  975   338     3 11638     8  6247    69    48 27354   598]\n",
      "true: 3232,   pr_ind: -1     proposed: [    9 10311 13275 11182 13505 18218 26072 24246 20030 11600]\n",
      "true: 8,      pr_ind: 2      proposed: [ 178  975    8    3   69   48 1499 1105   72   21]\n",
      "true: 1105,   pr_ind: 9      proposed: [1139 3911  975 3785  169 7221 1499 2291    3 1105]\n",
      "true: 12,     pr_ind: 0      proposed: [ 12 610  72   3  13 423 743 128   8  31]\n",
      "true: 817,    pr_ind: -1     proposed: [11610  6634   610 27354   854 21119  1738   356 18395 11435]\n",
      "true: 8,      pr_ind: 0      proposed: [    8    70   178   975  1193  1499     3 24228    69   445]\n",
      "true: 825,    pr_ind: 7      proposed: [ 358 1437 1499 2491 3911 1948 1218  825 1612 3381]\n",
      "true: 84,     pr_ind: 4      proposed: [  125  1776    12   149    84     8 11185    24     6    70]\n",
      "true: 1234,   pr_ind: 0      proposed: [ 1234 16513  1499  2850   753 12545  1467  1448  3785  1353]\n",
      "true: 398,    pr_ind: 4      proposed: [ 12  79  33 225 398  62 174  56   8  54]\n",
      "true: 36,     pr_ind: 0      proposed: [  36 2385 3480  560   59 2367 4093 3223  369   43]\n",
      "true: 1285,   pr_ind: 0      proposed: [ 1285     3   261 15459 19678  2546 21527   915  6126  3911]\n",
      "true: 16,     pr_ind: 1      proposed: [   5   16 1096   11  441   42    6  274  139   12]\n",
      "true: 8,      pr_ind: 0      proposed: [   8   70  165  284 3911   34 7314    3   46  125]\n",
      "true: 414,    pr_ind: -1     proposed: [ 3911   804  7314  1499  3785  6126   741     3 15459   772]\n",
      "true: 3911,   pr_ind: 2      proposed: [  18  741 3911 7314  556 1499  772    5 3785 1612]\n",
      "true: 5,      pr_ind: 0      proposed: [   5    7    6   13   11   42   41   12 1499  274]\n",
      "true: 1,      pr_ind: 0      proposed: [   1   86    3  100 1193   37  611  947  101  242]\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "proposed = torch.argsort(outputs.logits, dim=-1, descending=True)[:, :, :n].reshape(-1, n)\n",
    "true = labels.reshape(-1)\n",
    "\n",
    "for i in range(true.shape[0]):\n",
    "    j = -1\n",
    "    for j_ in range(n):\n",
    "        if true[i] == proposed[i][j_]:\n",
    "            j = j_\n",
    "    s = f\"true: {true[i]}, {' ' * (5 - len(str(true[i].item())))} pr_ind: {j} {' ' * (5 - len(str(j)))} proposed: {proposed[i].data.numpy()}\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c8f759f-cd81-481d-9230-dcc77e178a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84a866-1f4a-48ea-ae0b-50d7c1b5752f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11aa2728-d7b8-4905-a318-3fa452e593ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = \"EleutherAI/gpt-neo-2.7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e142098b-76d6-4a5c-82ac-4ba15bc66309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "950dda94-7628-4751-b7cb-cb999d9233ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt = GPTNeoForCausalLM.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ca333-6762-4614-b965-191d2ad8dad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2b31fe7-e775-4d46-8375-6b0b7d69eb24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(text_cond, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = gpt(input_ids=input_ids, labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "889a884d-9a61-442b-a24c-16a4e1b23c54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2333, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(outputs.logits.reshape(-1, 50257)[:-1], input_ids.reshape(-1)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b95d37e-8581-4e7d-b573-b3aa923caf79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: 8850,   pr_ind: -1     proposed: [262 867 257 428 749 584 883 674 616 287]\n",
      "true: 15584,  pr_ind: -1     proposed: [ 661 1692 5384 4290 1450 3788   11 3644 3925 5006]\n",
      "true: 2989,   pr_ind: -1     proposed: [15464    12 19702 14583  6626 21103 43813 23610  3777  5289]\n",
      "true: 11,     pr_ind: 0      proposed: [   11 16113  5050  3341  7605  2761   290   393  9021 10064]\n",
      "true: 31070,  pr_ind: -1     proposed: [  262   674   356   257   428   543   810 15584   287   281]\n",
      "true: 15584,  pr_ind: 1      proposed: [ 2989 15584 23989    12  1957  4738  4696   416   850  1366]\n",
      "true: 2989,   pr_ind: 0      proposed: [ 2989 15455    12 10342 15464 12947   198   357 23989 21976]\n",
      "true: 3578,   pr_ind: 4      proposed: [  357   318   460   468  3578  7228   685  3544 12031    11]\n",
      "true: 514,    pr_ind: 4      proposed: [  262   257   284   329   514   530 15584   345   281   517]\n",
      "true: 284,    pr_ind: 0      proposed: [ 284  407  198   11  262  257 2989  357  691  517]\n",
      "true: 17596,  pr_ind: -1     proposed: [ 2989  1064   779 18306  1620 14561  7301  4646  2987  3292]\n",
      "true: 1630,   pr_ind: 1      proposed: [  517  1630   257   617  3734  3224 28619  1336   281   262]\n",
      "true: 625,    pr_ind: 0      proposed: [ 625  319  287  290  286  284  416   11  379 2402]\n",
      "true: 262,    pr_ind: 0      proposed: [  262   543   703   674   810   257  2989 15584   644  1111]\n",
      "true: 5072,   pr_ind: -1     proposed: [ 2989 15584  1271  3292  3081 26741  2546 11862  2033  6356]\n",
      "true: 286,    pr_ind: 0      proposed: [  286 15584    13  6082   416    11  2989  4610 12867  8379]\n",
      "true: 2420,   pr_ind: -1     proposed: [  262 15584   674   257  1123   281  2989 26741   597   428]\n",
      "true: 5270,   pr_ind: -1     proposed: [ 2989    12 10342    13 17923 15455    11 12336 20743 15676]\n",
      "true: 13,     pr_ind: 0      proposed: [   13   416    11   290   287  3341  1429 16113   981   685]\n",
      "true: 770,    pr_ind: 3      proposed: [  554   383   775   770   198  1482  1114  2750   632 22426]\n",
      "true: 318,    pr_ind: 0      proposed: [  318  1630   460  3578  8173  1724  3348  2665 13536  2099]\n",
      "true: 4465,   pr_ind: 3      proposed: [ 8793   780  3573  4465  2592  1760   257  1593 13013   287]\n",
      "true: 780,    pr_ind: 3      proposed: [ 329  287  618  780   11  355  284  611 1201  407]\n",
      "true: 356,    pr_ind: 2      proposed: [  340   262   356    11   287   257  2420 15584   674   749]\n",
      "true: 3360,   pr_ind: -1     proposed: [ 460  765  743  389  466  836 1690 1244  423  760]\n",
      "true: 760,    pr_ind: 5      proposed: [ 765  761  423 4601  466  760  836 2421 6227  691]\n",
      "true: 3446,   pr_ind: 6      proposed: [ 262  287  326  644  257  517 3446  617  703  543]\n",
      "true: 644,    pr_ind: 0      proposed: [ 644  543  703  262  810 1635  618  287   11 1521]\n",
      "true: 356,    pr_ind: 0      proposed: [ 356  262  257  674 5072 2456  284 2420  318 1611]\n",
      "true: 765,    pr_ind: 0      proposed: [ 765  389  561  447  761  821 4601 1612 1549  836]\n",
      "true: 2641,   pr_ind: -1     proposed: [284 262 674  11 422 287 475 257 503 290]\n",
      "true: 262,    pr_ind: 1      proposed: [ 257  262  674  286  281 2420  617  503 1123 4963]\n",
      "true: 5072,   pr_ind: 3      proposed: [ 2420  2989  3188  5072  5128 35789  2496 15584 17778  6827]\n",
      "true: 13,     pr_ind: 3      proposed: [  11 2420  286   13  475  290  357   26 2272   25]\n",
      "true: 1114,   pr_ind: 0      proposed: [ 1114   198   554   775   770   383  2102 12642  1002  1482]\n",
      "true: 1672,   pr_ind: 0      proposed: [1672 4554  428  262  257  674 2420  617  777  867]\n",
      "true: 11,     pr_ind: 0      proposed: [   11    25   356   611   287   618   262   257  2074 11691]\n",
      "true: 287,    pr_ind: 3      proposed: [  356   611 11691   287   618  2074   262   257  5967  1813]\n",
      "true: 257,    pr_ind: 1      proposed: [  262   257   674   428   617   281  4572  2420 11291   867]\n",
      "true: 47986,  pr_ind: -1     proposed: [2420 2989 3315 3188 3303 1339 1705 4046 6827 1808]\n",
      "true: 10850,  pr_ind: 0      proposed: [10850 39141  7311 17738 15417  8255   309 45835  3602    12]\n",
      "true: 33322,  pr_ind: 0      proposed: [33322 11059  3602 11725 18252 48313 41519 33417  8255 25342]\n",
      "true: 4876,   pr_ind: 2      proposed: [ 357 1080 4876 2746   11 4482 4634 1917 3586 8883]\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "proposed = torch.argsort(outputs.logits.reshape(-1, 50257)[:-1], dim=-1, descending=True)[:, :n].reshape(-1, n)\n",
    "true = input_ids.reshape(-1)[1:]\n",
    "\n",
    "for i in range(true.shape[0]):\n",
    "    j = -1\n",
    "    for j_ in range(n):\n",
    "        if true[i] == proposed[i][j_]:\n",
    "            j = j_\n",
    "    s = f\"true: {true[i]}, {' ' * (5 - len(str(true[i].item())))} pr_ind: {j} {' ' * (5 - len(str(j)))} proposed: {proposed[i].data.numpy()}\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433ad55-1a55-45b5-9f52-81adcd627c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae3813-c810-47f2-bbef-9b3a1410bad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37b2a974-4156-45ef-b95d-460df5249ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b23d5414-90cc-4995-8c1a-06f211cc94ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed804b96dd346bdbc1775bece5d8c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-base\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 3072,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"relu\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": false,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.21.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoConfig.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a030289-1ac1-4a95-9e90-a028715c4ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3-env]",
   "language": "python",
   "name": "conda-env-anaconda3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
