{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a419508e-0bc4-448c-bc32-d60dc678e453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18500599-08da-4ab3-8584-17f01568ce6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertLMHeadModel, BertTokenizerFast, BertConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import cross_entropy\n",
    "from tqdm import tqdm\n",
    "import ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c61bb36-7d1f-45b1-97d2-80afb8e24d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusion_utils import schedulers\n",
    "from diffusion_holder import DiffusionRunner\n",
    "from utils.util import set_seed, dict_to_cuda\n",
    "from estimation_utils.estimate_glue import estimate_sst2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c27a1-1712-45b0-bf30-26d202ea3bd0",
   "metadata": {},
   "source": [
    "# SST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c5437c4-146f-44a0-976a-22f4249e8d02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "    optim = config.optim = ml_collections.ConfigDict()\n",
    "    optim.grad_clip_norm = 1.\n",
    "    optim.linear_warmup = 0\n",
    "    optim.lr = 2e-4\n",
    "    optim.min_lr = 2e-4\n",
    "    optim.warmup_lr = 2e-4\n",
    "    optim.weight_decay = 0.01\n",
    "    optim.beta_1 = 0.9\n",
    "    optim.beta_2 = 0.98\n",
    "    optim.eps = 1e-6\n",
    "\n",
    "    training = config.training = ml_collections.ConfigDict()\n",
    "    training.training_iters = 400_000\n",
    "    training.finetuning_iters = 10_000\n",
    "    training.training_iters = training.training_iters + training.finetuning_iters\n",
    "    training.checkpoint_freq = 1_000\n",
    "    training.eval_freq = 1_000\n",
    "    training.batch_size = 512\n",
    "\n",
    "    training.ode_sampling = False\n",
    "    training.checkpoints_folder = '../checkpoints/'\n",
    "    config.checkpoints_prefix = ''\n",
    "\n",
    "    loss = config.loss = ml_collections.ConfigDict()\n",
    "    loss.ce_coef = 0.\n",
    "\n",
    "    refresh = config.refresh = ml_collections.ConfigDict()\n",
    "    refresh.true = True\n",
    "    refresh.prefix = \"\"\n",
    "    refresh.wand_id = \"g5fb4af3\"\n",
    "\n",
    "    validation = config.validation = ml_collections.ConfigDict()\n",
    "    validation.batch_size = 1024\n",
    "    validation.validation_iters = int(10_000 / validation.batch_size)\n",
    "    validation.num_gen_texts = 2048\n",
    "    validation.p_uncond = 0.\n",
    "\n",
    "    sde = config.sde = ml_collections.ConfigDict()\n",
    "    sde.typename = 'vp-sde'\n",
    "    sde.solver = 'euler'\n",
    "    sde.N = 1000\n",
    "    sde.beta_min = 0.1\n",
    "    sde.beta_max = 20\n",
    "    sde.ode_sampling = False\n",
    "    sde.scheduler = schedulers.CosineSD(d=10)\n",
    "\n",
    "    model = config.model = ml_collections.ConfigDict()\n",
    "    model.ema_rate = 0.9999\n",
    "    model.enc_type = \"base\"\n",
    "    model.embeddings_type = \"encodings\"\n",
    "    model.dif_enc_type = \"base\"\n",
    "    model.downstream_task = \"sst2\"  # \"qqp\"\n",
    "    model.dataset = \"glue\"  # \"glue\"\n",
    "    model.prediction = \"x_0\"\n",
    "    model.loss = \"L_x_0\"\n",
    "\n",
    "    data = config.data = ml_collections.ConfigDict()\n",
    "    data.max_sequence_len = 64\n",
    "\n",
    "    config.lin_input = True\n",
    "    config.seed = 0\n",
    "    config.ddp = False\n",
    "    config.bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fd788aa-4afb-4552-91ba-83d537a5d0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = create_config()\n",
    "config.checkpoints_prefix = \"glue-sst2-encodings-prediction=x_0-loss=L_x_0-enc=base-bert=base-kl_cf=0.0-seq_len=64-clipgrad=1.0-lr=0.0002-min_lr=0.0002-lin_input=True-seed=0-wd=0.01-glue-sst2_405000_\"\n",
    "\n",
    "seed = config.seed\n",
    "set_seed(seed)\n",
    "\n",
    "diffusion = DiffusionRunner(config, latent_mode=\"encodings\", eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004b75ae-b48b-4a45-a9d4-3304914a21f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/anaconda3/envs/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 1000/1000 [02:13<00:00,  7.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(113.0, 128.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_sst2(diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "071024f6-5045-4dc6-a02f-840a85d1e4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffusion.set_valid_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "957c6ebf-9f3d-457f-b011-b449bedfb841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, device='cuda:0') torch.Size([872])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X = next(iter(diffusion.valid_loader))\n",
    "    X = dict_to_cuda(X)\n",
    "    clean_X = diffusion.sampler_emb({\"input_ids\": X[\"input_ids\"], \"attention_mask\": X[\"input_mask\"]})\n",
    "    output = diffusion.decoder(clean_X)\n",
    "    tokens = output.argmax(dim=-1)\n",
    "    target = tokens[:, 1]\n",
    "    label = X[\"input_ids\"][:, 1]\n",
    "    print(torch.mean((target == label) * 1.), target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68196688-eeba-4d6a-84dd-0c141a01c63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b969c31-8fa1-4dbe-ad04-7e201e557734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3-env]",
   "language": "python",
   "name": "conda-env-anaconda3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
