{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6732da72-abf3-4271-b76e-7daffc5c0647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5936c14-f2b9-4e56-9413-5bc3b4a054cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684093ba-4279-4a41-aa50-4f4cf5ca9782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5496c2dc-95fe-4224-9511-f07f0690a114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.dataset_clean_wiki import WikipediaCleanDatasetUnconditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ce1312-1dff-4aa3-a7fc-168f0cf87957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0919eb-ce62-497b-882a-632c9047e836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9ff253-7063-4c52-9114-ae1f3aa22b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightning import seed_everything, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c42ae5a-2f0a-4377-8f2f-4991a7270d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a19d2-4d50-4347-94f9-beaa359f190f",
   "metadata": {},
   "source": [
    "# GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36f6415-1b78-4da4-8a91-fb0545cf1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1bb328-74cd-4c35-91ce-ec20cffb74a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f31b29c1-901b-419e-b38e-4de3b5f13d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = 50256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7289218-9510-4265-84ad-a0891d431175",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c6beb55-c77a-4325-951b-5d2d7af8e5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = next(WikipediaCleanDatasetUnconditional(\n",
    "    split=\"test\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_sequence_len=128,\n",
    ").get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae5fd773-9e9a-4871-be3b-b024674b1349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c072bcd8-a480-4def-ac44-f66ec631e529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cb12440-12e9-4c49-a4b2-d39bc0fbb7b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits = gpt2(**X).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6cf15c0c-47b8-4659-bd97-55dc943b4da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 50257])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e84f335-b659-4ec8-8f2f-1552a71fa7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aca78d8f-61f4-4563-893a-ff5a7c7f09e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = X[\"input_ids\"]\n",
    "mask = X[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9317e56f-02d3-429e-85cd-32790cde1963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1708, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0f8829e1-157a-4e86-8f17-247165ce563f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.29.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ddf16a-30f9-48b2-82fa-bcdb8b13c197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "09e15cfe-0059-40db-8ecf-ba1e1c993f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPTModel(L.LightningModule):\n",
    "    def __init__(self,):\n",
    "        super(GPTModel, self).__init__()\n",
    "        # Model Architecture\n",
    "        self.gpt_config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "        self.model = AutoModelForCausalLM.from_config(self.gpt_config)\n",
    "    \n",
    "    def recon_loss(self, inputs, outputs, mask=None):\n",
    "        if mask is None:\n",
    "            mask = torch.ones(\n",
    "                (inputs.shape[0], inputs.shape[1]),\n",
    "                requires_grad=False,\n",
    "                dtype=torch.int64,\n",
    "            )\n",
    "        \n",
    "        losses = cross_entropy(\n",
    "            input=inputs.reshape(-1, inputs.shape[-1]),\n",
    "            target=outputs.reshape(-1),\n",
    "            reduce=False,\n",
    "        )\n",
    "        losses = losses * mask.reshape(-1)\n",
    "        loss = torch.sum(losses) / torch.sum(mask)\n",
    "        return loss\n",
    "    \n",
    "    def get_loss(self, logits, targets, mask):\n",
    "        loss = self.recon_loss(logits[:, :-1], targets[:, 1:], mask[:, 1:])\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, X):\n",
    "        logits = self.model(**X).logits\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        target = batch[\"input_ids\"]\n",
    "        mask = batch[\"attention_mask\"]\n",
    "        \n",
    "        logits = self.forward(batch)\n",
    "        loss = self.get_loss(logits, target, mask)\n",
    "        \n",
    "        logs = {'loss': loss}\n",
    "        # if self.config.wandb:\n",
    "        #     wandb_log(loss=loss.item())\n",
    "        return {'loss': loss, 'log': logs}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.model.parameters(), lr=1e-4, weight_decay=0)\n",
    "        return [opt], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1a072a1b-a7a4-4480-ac88-29b9f065e229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "97b7ccf1-b542-4e23-8719-65db0fdc8c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e9cf776-0b09-4fee-9a70-ebc6d8efe69e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | GPT2LMHeadModel | 124 M \n",
      "------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "497.759   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b93d723a230462fbcaf636ac0c77a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274264a3-c292-492a-bcbc-5ed0521a2270",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2dac09-9c80-40e3-99b9-c54e1018ff9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f540084a-2b43-4e9f-8eed-e38ff2022b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f9d0f6-e5a4-4347-9716-ce554e906b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9700f75-296f-475c-ba93-d779aabefab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert = BertForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88070614-ea94-42af-9a54-66ade1b61a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = next(WikipediaCleanDatasetUnconditional(\n",
    "    split=\"test\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_sequence_len=128,\n",
    ").get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85fc91d1-669b-4e3f-97ba-0f8db4dba5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=True, \n",
    "    mlm_probability=0.15,\n",
    "    pad_to_multiple_of=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1be0a6c2-e6a9-4fce-a9d4-4d19c893b627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=2, \n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5516d61f-ec9f-40fa-a9b3-f6b9493457a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "X = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f92986c1-42c4-45b9-83b9-e84fb039bf23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde4146-dddb-4b91-a74a-a0b0c53b1546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-fap2_env]",
   "language": "python",
   "name": "conda-env-.conda-fap2_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
