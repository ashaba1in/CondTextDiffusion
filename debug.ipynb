{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c8c648-6f5a-4624-a540-9eac55fad292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c335f086-25a1-461f-bfe4-02733698de7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/anaconda3/envs/env/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/vmeshchaninov/anaconda3/envs/env/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import torch.distributed as dist\n",
    "import ml_collections\n",
    "from datasets import disable_progress_bar\n",
    "from transformers import BertConfig\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/\")\n",
    "\n",
    "from diffusion_holder import DiffusionRunner\n",
    "from utils.util import set_seed, _BERT_SMALL\n",
    "from estimation_utils.util import estimate_model, reduce_metrics, gather_texts\n",
    "import diffusion_utils.schedulers as schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1a73b7-da43-4ee5-b0ed-5eb40a2f35dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    training = config.training = ml_collections.ConfigDict()\n",
    "    training.ode_sampling = False\n",
    "    training.checkpoints_folder = './checkpoints'\n",
    "    training.batch_size = 512\n",
    "    config.checkpoints_prefix = None\n",
    "\n",
    "    validation = config.validation = ml_collections.ConfigDict()\n",
    "    validation.batch_size = 512\n",
    "\n",
    "    sde = config.sde = ml_collections.ConfigDict()\n",
    "    sde.typename = 'vp-sde'\n",
    "    sde.solver = 'euler'\n",
    "    sde.N = 100\n",
    "    sde.beta_min = 0.1\n",
    "    sde.beta_max = 20\n",
    "    sde.ode_sampling = False\n",
    "    sde.scheduler = schedulers.CosineSD(d=10)\n",
    "\n",
    "    model = config.model = ml_collections.ConfigDict()\n",
    "    model.ema_rate = 0.9999\n",
    "    model.enc_type = \"base\"\n",
    "    model.embeddings_type = \"encodings\"\n",
    "    model.dif_enc_type = \"base\"\n",
    "    model.downstream_task = \"sst2\"  # \"qqp\"\n",
    "    model.dataset = \"wikipedia\"  # \"glue\"\n",
    "    model.prediction = \"x_0\"\n",
    "    model.loss = \"L_x_0\"\n",
    "    model.decoder_path = \"decoder-wikipedia-128.pth\"  # \"decoder-wikipedia-128.pth\"  # \"decoder-t5_base-wikipedia-128.pth\"\n",
    "\n",
    "    data = config.data = ml_collections.ConfigDict()\n",
    "    data.max_sequence_len = 96\n",
    "    data.enc_bert_mean = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-bert_base-wiki-mean.pt\"\n",
    "    data.enc_bert_std = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-bert_base-wiki-std.pt\"\n",
    "    data.enc_t5_mean = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-t5-wiki-mean.pth\"\n",
    "    data.enc_t5_std = \"/home/vmeshchaninov/DiffusionTextGeneration-cond-ca/data/encodings-t5-wiki-std.pth\"\n",
    "\n",
    "    config.finetuning = False\n",
    "    config.seed = 0\n",
    "    config.ddp = False\n",
    "    config.bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    config.project_name = \"bert-conditional-exps\"\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438c64ed-97bd-4959-a084-e400668b4322",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmeshchaninov/anaconda3/envs/env/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at t5-base were not used when initializing T5EncoderModel: ['decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.final_layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5EncoderModel were not initialized from the model checkpoint at t5-base and are newly initialized: ['enc_normalizer.enc_mean', 'enc_normalizer.enc_std']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoderModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertEncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertEncoderModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['enc_normalizer.enc_mean', 'enc_normalizer.enc_std']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = create_config()\n",
    "config.checkpoints_prefix = \"wikipedia-sst2-encodings-prediction=x_0-loss=L_x_0-enc=base-bert=base-kl_cf=0.0-seq_len=96-clipgrad=1.0-lr=0.0002-min_lr=0.0002-lin_input=True-seed=0-wd=0.01-ting-pretrain_200000_\"\n",
    "\n",
    "diffusion = DiffusionRunner(config, latent_mode=config.model.embeddings_type, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b312626-bdb0-4ea9-9aa3-7f0dacf18c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "seq_len = 96\n",
    "mask = torch.ones(batch_size, seq_len).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429ca3eb-129a-4c45-b3cc-5910c0f1f19d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise = torch.load(\"data/noise.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9507dc19-3e8e-458d-b73c-183dc1835762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_embeddings, outputs = diffusion.pred_embeddings(\n",
    "    batch_size=batch_size,\n",
    "    cond_X=noise.cuda(),\n",
    "    cond_mask=None,\n",
    "    attention_mask=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cae1b0-c53d-44a5-b22f-403465080fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 96, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e924221a-7309-40f6-8c5d-3364fa3609ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1.0, 0.9900000095367432, 0.9800000190734863, 0.9700000286102295, 0.9599999785423279, 0.949999988079071, 0.9399999976158142, 0.9300000071525574, 0.9200000166893005, 0.9100000262260437, 0.8999999761581421, 0.8899999856948853, 0.8799999952316284, 0.8700000047683716, 0.8600000143051147, 0.8500000238418579, 0.8400000333786011, 0.8299999833106995, 0.8199999928474426, 0.8100000023841858, 0.800000011920929, 0.7900000214576721, 0.7800000309944153, 0.7699999809265137, 0.7599999904632568, 0.75, 0.7400000095367432, 0.7300000190734863, 0.7200000286102295, 0.7099999785423279, 0.699999988079071, 0.6899999976158142, 0.6800000071525574, 0.6700000166893005, 0.6600000262260437, 0.6500000357627869, 0.6399999856948853, 0.6299999952316284, 0.6200000047683716, 0.6100000143051147, 0.6000000238418579, 0.5900000333786011, 0.5799999833106995, 0.5699999928474426, 0.5600000023841858, 0.550000011920929, 0.5400000214576721, 0.5300000309944153, 0.5199999809265137, 0.5099999904632568, 0.5, 0.4899999797344208, 0.47999998927116394, 0.4699999988079071, 0.4599999785423279, 0.44999998807907104, 0.4399999976158142, 0.429999977350235, 0.41999998688697815, 0.4099999964237213, 0.3999999761581421, 0.38999998569488525, 0.3799999952316284, 0.3700000047683716, 0.35999998450279236, 0.3499999940395355, 0.3400000035762787, 0.32999998331069946, 0.3199999928474426, 0.3100000023841858, 0.29999998211860657, 0.28999999165534973, 0.2800000011920929, 0.26999998092651367, 0.25999999046325684, 0.25, 0.23999999463558197, 0.22999998927116394, 0.2199999988079071, 0.20999999344348907, 0.19999998807907104, 0.1899999976158142, 0.17999999225139618, 0.17000000178813934, 0.1599999964237213, 0.14999999105930328, 0.14000000059604645, 0.12999999523162842, 0.11999999731779099, 0.10999999940395355, 0.09999999403953552, 0.08999999612569809, 0.07999999821186066, 0.07000000029802322, 0.05999999865889549, 0.04999999701976776, 0.03999999910593033, 0.029999999329447746, 0.019999999552965164, 0.009999999776482582])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d96e5eb6-85cc-4f75-8354-add09398e974",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x', 'x_mean', 'score', 'x_0', 'diffusion', 'drift', 'drift_par'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1.0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d93ef2-85b2-4561-a92e-52b73264e874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(outputs, \"outputs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26a9741-eb88-4669-a8f0-c7f7891fbd71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = torch.load(\"outputs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b94353-7d1f-4a82-a8c8-1a916ed2504b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2375,  0.3566, -0.3443,  ..., -0.9245,  0.1156,  0.1162],\n",
       "         [ 0.1872,  0.3632,  1.6989,  ...,  0.7197, -0.5856, -0.6825],\n",
       "         [-0.5971, -0.1787,  0.1655,  ...,  0.3111, -0.3182, -0.9170],\n",
       "         ...,\n",
       "         [-0.3196, -0.8789,  0.7730,  ..., -0.1017,  0.6921, -0.1522],\n",
       "         [-0.3990,  0.0837, -0.4579,  ..., -0.2317, -0.4622,  0.0244],\n",
       "         [-0.0850,  0.6905, -0.1843,  ...,  0.8798,  2.1656, -1.9218]],\n",
       "\n",
       "        [[-0.5513, -0.3091, -0.6040,  ..., -0.1974,  1.4466, -0.5213],\n",
       "         [-0.5075,  1.7510, -0.8983,  ...,  2.1446,  0.7130,  0.0743],\n",
       "         [ 0.6342,  0.1784,  1.0736,  ...,  0.8481, -1.9557, -1.2758],\n",
       "         ...,\n",
       "         [-1.0950, -0.5760,  0.0230,  ...,  1.3681,  1.2309, -0.7965],\n",
       "         [-0.1822,  0.0809,  0.5066,  ..., -1.1838, -0.1984, -0.1939],\n",
       "         [ 0.2550,  0.5510,  0.2364,  ...,  1.4841,  1.0805, -1.7359]],\n",
       "\n",
       "        [[-1.3289,  1.7212, -1.0028,  ..., -0.1714,  1.2455, -0.8029],\n",
       "         [ 1.6172, -1.8103,  1.1269,  ...,  0.3412, -0.3361,  0.6958],\n",
       "         [-1.0901, -1.1091,  0.3205,  ...,  0.6282, -1.1827, -1.3541],\n",
       "         ...,\n",
       "         [ 0.2734,  0.1373, -0.5887,  ..., -1.0165, -1.5021,  1.1955],\n",
       "         [-0.6689, -1.0615, -1.2103,  ...,  0.8289,  0.4401, -0.6536],\n",
       "         [-0.4011,  0.2798, -1.5293,  ...,  1.6736,  1.1694, -0.8972]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.6698,  1.0686, -0.5294,  ..., -0.7021,  0.1908,  1.7344],\n",
       "         [-0.0418,  0.8653, -0.3688,  ...,  0.5177,  0.6520, -0.9488],\n",
       "         [ 1.1787, -0.3667,  1.1102,  ...,  0.2193,  1.1166,  0.6320],\n",
       "         ...,\n",
       "         [-0.0644,  0.1083,  1.1844,  ..., -0.2591,  0.3252,  0.7940],\n",
       "         [ 0.0556,  0.4770, -0.4084,  ...,  0.4612, -1.1287, -0.0187],\n",
       "         [ 1.1797,  1.6636,  0.4417,  ...,  0.6483,  1.2658, -0.7622]],\n",
       "\n",
       "        [[-1.4196,  1.0731,  0.4385,  ..., -0.7199,  1.1532,  1.1519],\n",
       "         [-2.0220, -0.6528,  0.2250,  ...,  0.6937,  1.4902, -0.4548],\n",
       "         [-0.3178,  0.4057,  0.2196,  ..., -0.2068,  0.6208,  0.6979],\n",
       "         ...,\n",
       "         [-0.5552, -0.8253,  1.6206,  ..., -0.2596,  0.4046,  0.0912],\n",
       "         [-1.2825,  0.7116,  0.0549,  ...,  0.2125, -1.4365, -0.2023],\n",
       "         [ 1.5467,  1.4417,  0.0833,  ...,  0.0994,  1.8267, -0.3098]],\n",
       "\n",
       "        [[-0.5694,  0.1787,  0.2120,  ..., -0.3414,  0.2300,  0.8612],\n",
       "         [ 0.0553,  0.3713,  0.0477,  ...,  1.6390,  0.2991, -0.2051],\n",
       "         [-0.2302,  0.8780,  0.0127,  ...,  1.2293,  0.2884, -0.5711],\n",
       "         ...,\n",
       "         [-0.0273,  0.0696,  1.1879,  ..., -1.4290,  0.6311, -1.6782],\n",
       "         [ 0.9684, -0.3835,  0.1866,  ...,  0.5431, -0.4489,  0.1436],\n",
       "         [ 0.6150,  0.6756,  1.3464,  ..., -0.5887,  0.0491, -0.2749]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0.009999999776482582][\"x_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5bcf777-f011-4658-bd6d-2e3824d04fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion.decoder.load_state_dict(torch.load(\"./checkpoints/decoder-wikipedia-128.pth\")[\"decoder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9a3da70-10d2-40bf-a2ec-0d6963f53e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('predictions.bias',\n",
       "              tensor([-0.4030, -0.4316, -0.4306,  ..., -0.8043, -0.8011, -0.5078],\n",
       "                     device='cuda:0')),\n",
       "             ('predictions.transform.dense.weight',\n",
       "              tensor([[ 0.5829, -0.0084,  0.0793,  ...,  0.0357, -0.0230,  0.0262],\n",
       "                      [-0.0051,  0.3722, -0.0640,  ..., -0.0260, -0.0248,  0.0135],\n",
       "                      [ 0.0137, -0.0793,  0.2726,  ...,  0.0437,  0.0706, -0.0374],\n",
       "                      ...,\n",
       "                      [ 0.0406,  0.0040,  0.0366,  ...,  0.4009,  0.0165, -0.0415],\n",
       "                      [-0.0009, -0.0414,  0.0658,  ...,  0.0038,  0.2923, -0.0669],\n",
       "                      [-0.0857,  0.0041,  0.0371,  ...,  0.0188, -0.0441,  0.5341]],\n",
       "                     device='cuda:0')),\n",
       "             ('predictions.transform.dense.bias',\n",
       "              tensor([ 7.2733e-02,  8.9592e-02,  8.0551e-02,  4.4807e-03,  5.3272e-02,\n",
       "                       2.5110e-03,  2.8013e-02,  3.0577e-03,  4.4827e-02,  1.2519e-01,\n",
       "                       6.2096e-02,  5.4720e-02,  2.3361e-02,  7.1210e-02,  6.5986e-02,\n",
       "                       2.7879e-02,  9.2104e-02,  3.3852e-02,  6.6448e-02,  8.4068e-02,\n",
       "                       9.2872e-02,  6.7008e-02,  6.3930e-02,  4.3054e-02,  9.6452e-02,\n",
       "                       5.8445e-02,  5.3034e-02,  3.8321e-02,  4.4861e-02,  2.4781e-02,\n",
       "                       9.8956e-04,  6.9129e-02,  6.9516e-02,  8.1683e-02,  8.6449e-02,\n",
       "                       5.0539e-02,  3.0598e-02,  6.7833e-02,  3.2665e-02,  4.4017e-02,\n",
       "                       2.4633e-02,  5.0729e-02,  3.4700e-02,  6.3647e-02,  5.5225e-02,\n",
       "                       4.7638e-02,  6.9936e-02,  2.4312e-02,  6.1142e-02,  4.5907e-02,\n",
       "                       2.6629e-02,  4.7963e-02,  7.6545e-02, -1.4295e-01,  8.0512e-02,\n",
       "                       5.9303e-02,  8.6279e-02,  5.5757e-02,  6.0533e-02,  5.5416e-02,\n",
       "                       3.6568e-02,  4.5931e-02, -7.2262e-02,  1.1830e-02,  9.2294e-02,\n",
       "                       4.7462e-02,  9.5317e-02,  6.6769e-02,  5.1753e-02,  8.2842e-02,\n",
       "                       2.2720e-02,  7.2092e-03,  6.6532e-02,  4.9949e-02,  2.7475e-02,\n",
       "                       4.5236e-02,  1.3074e-02,  3.9747e-02,  4.8455e-02,  3.0196e-02,\n",
       "                       2.5716e-02,  1.0100e-02,  8.3158e-02,  5.9613e-02,  5.4299e-02,\n",
       "                       7.4222e-02,  5.9641e-02,  2.5195e-02,  6.0970e-02,  6.5775e-02,\n",
       "                       8.6445e-02,  6.7813e-02,  6.4594e-02,  7.3624e-02,  5.5538e-02,\n",
       "                       6.1130e-02,  2.6758e-02,  4.7812e-02,  4.8032e-02,  4.5659e-02,\n",
       "                       6.9730e-02,  2.3699e-02,  7.3163e-02,  6.0309e-02,  7.4435e-02,\n",
       "                      -5.4378e-02,  1.3849e-02,  6.5210e-02,  4.6749e-02,  6.0674e-02,\n",
       "                       2.2124e-02,  6.7809e-02,  6.5354e-02, -5.2263e-03,  6.8507e-02,\n",
       "                       4.6881e-02,  3.8757e-02,  6.3313e-02,  3.0156e-02,  5.3957e-02,\n",
       "                       5.8660e-02,  3.4819e-02,  2.7754e-02,  7.0546e-02,  1.1823e-01,\n",
       "                       2.3866e-02,  5.3021e-02,  7.0640e-02,  2.4242e-02,  2.5999e-02,\n",
       "                       6.3497e-02, -9.7215e-03, -7.2052e-03,  5.8333e-02,  3.2218e-02,\n",
       "                       6.7008e-02,  7.6841e-02,  5.2775e-02,  6.1333e-02, -7.1390e-02,\n",
       "                       8.9716e-02,  1.3152e-02,  3.0020e-02,  5.4818e-02,  4.6487e-02,\n",
       "                       3.6726e-02,  7.5314e-02,  1.2076e-01,  1.7887e-02,  3.1573e-02,\n",
       "                       9.2528e-02,  5.3620e-02,  4.7486e-02,  4.2552e-02,  2.6942e-02,\n",
       "                       2.4528e-02,  4.2014e-02,  7.0310e-02,  1.7707e-02, -9.5481e-02,\n",
       "                       3.1206e-03,  3.2671e-02,  7.8342e-03,  2.2319e-02,  2.0278e-02,\n",
       "                       1.6595e-02,  5.7809e-02,  8.0836e-02, -6.9315e-02,  1.8209e-02,\n",
       "                       2.3857e-02,  6.6605e-02,  7.5952e-02,  3.6535e-02,  4.0373e-02,\n",
       "                      -1.1076e-01,  4.4424e-02,  5.2874e-02,  6.1935e-02,  6.3363e-02,\n",
       "                       3.7798e-02,  5.1578e-06,  4.6870e-02,  1.2660e-02,  1.8063e-02,\n",
       "                       5.1740e-02,  6.5333e-02,  6.8759e-02,  2.8279e-02,  1.1627e-02,\n",
       "                       2.2187e-02,  4.4184e-02,  3.0757e-02,  6.1022e-02,  6.7009e-03,\n",
       "                       1.5550e-02,  3.8835e-02,  4.3896e-02,  5.3984e-02,  3.4340e-02,\n",
       "                       2.3116e-02,  7.0316e-02, -6.1969e-02,  4.8614e-02,  5.4411e-02,\n",
       "                       5.1376e-02,  1.4023e-02,  2.9682e-02,  1.0349e-02,  7.7367e-02,\n",
       "                       7.1130e-02,  5.9553e-02,  7.0534e-02,  6.1511e-02,  6.3058e-02,\n",
       "                      -6.8682e-02, -5.5205e-02,  8.0151e-02, -8.9849e-02,  7.2707e-02,\n",
       "                       6.7223e-02,  4.6381e-02,  1.7010e-02,  7.4286e-02,  6.3944e-02,\n",
       "                      -1.3022e-01,  3.2274e-02,  5.1677e-02,  1.1368e-02,  2.3029e-02,\n",
       "                       8.9198e-03,  4.1805e-02,  8.0459e-02,  1.4708e-02,  2.5774e-02,\n",
       "                       3.7564e-02,  4.6080e-02,  3.9101e-02,  7.6915e-02,  6.2791e-02,\n",
       "                       3.9948e-02,  4.3120e-02,  1.3906e-02,  4.8816e-03,  3.3232e-02,\n",
       "                      -1.0558e-01,  4.4790e-02,  1.1634e-01,  8.0652e-02, -2.8127e-02,\n",
       "                       1.6837e-02,  5.5636e-02,  7.4822e-02,  6.6765e-02,  3.7010e-02,\n",
       "                       6.0077e-02,  5.4683e-02,  6.3131e-02,  5.7752e-02,  6.6640e-02,\n",
       "                       6.9310e-03,  3.9106e-03,  4.7360e-02,  8.1082e-02,  3.3693e-02,\n",
       "                       6.9281e-02,  5.9683e-02,  2.1884e-02,  2.0797e-02,  5.9727e-02,\n",
       "                       1.9377e-02,  4.8406e-02,  6.9769e-02,  3.0122e-02,  2.7506e-02,\n",
       "                       3.2387e-02,  6.2563e-02,  9.4343e-02,  6.3710e-02,  5.1345e-02,\n",
       "                       4.7387e-02,  1.9043e-02,  2.4219e-02, -5.5545e-02,  4.8397e-02,\n",
       "                       2.2390e-02,  2.5811e-02,  7.6670e-03,  1.3424e-02,  2.8911e-02,\n",
       "                       2.2260e-02, -7.9893e-02,  5.2772e-02,  1.3878e-02,  4.5625e-02,\n",
       "                       6.2067e-02, -4.2714e-02,  9.8411e-03,  1.3441e-02,  6.3895e-03,\n",
       "                       2.6273e-02,  3.5686e-02,  9.4922e-02,  7.7519e-02,  1.9657e-02,\n",
       "                       5.9773e-02,  6.6620e-02,  5.3058e-02, -3.4882e-02,  6.9609e-02,\n",
       "                       8.0249e-02, -9.1717e-02,  6.4335e-02,  4.1959e-02,  4.2919e-03,\n",
       "                       1.5485e-02,  2.9342e-02,  4.8323e-03,  4.9607e-02, -5.2044e-02,\n",
       "                       1.0703e-02,  5.0240e-02,  9.4078e-03, -1.3922e-03,  2.2419e-02,\n",
       "                       5.8766e-02,  5.7257e-02,  3.0724e-02,  6.1201e-02,  6.4788e-02,\n",
       "                       4.0560e-02, -7.8012e-02,  2.3921e-03,  2.4192e-02,  7.9616e-02,\n",
       "                       6.6884e-02,  4.6425e-02,  3.1430e-02,  6.9389e-02,  7.8734e-02,\n",
       "                       7.3519e-02,  4.4476e-04,  3.1018e-02,  5.3343e-02,  7.5547e-02,\n",
       "                      -3.2376e-02,  2.2400e-02,  6.6543e-03,  6.7828e-02,  7.3967e-02,\n",
       "                       1.8041e-01,  2.1804e-02,  5.6021e-02, -1.7279e-01,  4.7379e-02,\n",
       "                       1.0613e-02,  2.7507e-02,  3.4477e-02,  5.9643e-02,  5.5068e-02,\n",
       "                       9.6239e-02,  1.1148e-02,  5.0990e-02,  1.0851e-03,  6.5537e-02,\n",
       "                       1.7218e-02,  2.9720e-02, -6.5155e-03,  8.2876e-02,  4.5674e-03,\n",
       "                       6.5826e-02,  9.4885e-02,  6.4767e-02,  4.4136e-02,  1.9471e-02,\n",
       "                       1.3061e-01,  1.0554e-02,  6.9624e-03,  5.1227e-02,  6.7889e-02,\n",
       "                       7.4853e-02,  1.1800e-01,  2.2341e-02,  6.3085e-02,  5.5423e-02,\n",
       "                       2.1709e-02,  4.5300e-02,  7.0447e-02,  9.2184e-03,  5.2157e-02,\n",
       "                       1.2099e-02,  3.2106e-02,  3.8704e-02,  5.2611e-02,  4.1840e-02,\n",
       "                       4.8233e-02,  3.4553e-02,  3.6336e-02, -2.9415e-03,  8.8653e-02,\n",
       "                       6.0501e-02, -2.0770e-02,  1.3662e-01,  2.2692e-02,  5.6109e-02,\n",
       "                       4.1254e-02, -3.6537e-03,  6.7165e-02,  3.8720e-02,  2.8885e-02,\n",
       "                       1.8876e-02,  1.9241e-02,  1.5816e-02,  1.7392e-02,  5.9710e-02,\n",
       "                       5.4697e-02,  2.4761e-02,  7.0904e-02,  6.6231e-02,  2.2203e+00,\n",
       "                       7.1603e-02,  5.3799e-02,  3.0258e-02,  3.1195e-02,  1.0869e-01,\n",
       "                       6.0004e-02,  7.3804e-03,  4.0267e-03,  6.8004e-02,  2.7331e-02,\n",
       "                       9.9362e-03,  5.0560e-02,  4.5535e-02,  5.9907e-02,  6.5618e-02,\n",
       "                       1.3779e-02,  8.7873e-02,  5.9970e-02,  5.3214e-02,  5.8646e-02,\n",
       "                       7.6174e-02,  6.3865e-02,  2.5035e-02, -1.4984e-01,  1.6374e-02,\n",
       "                       6.3783e-02,  4.2679e-02,  4.5463e-02,  2.1883e-02,  1.3805e-02,\n",
       "                      -2.0011e-03,  4.4646e-03,  5.6409e-02,  6.6416e-02,  3.8429e-02,\n",
       "                       4.4011e-02,  1.6110e-02,  1.8836e-02,  5.8020e-02,  5.8817e-02,\n",
       "                       4.2348e-02, -7.9557e-02,  7.2538e-02,  6.5599e-02,  3.8413e-02,\n",
       "                       2.2801e-02,  5.8174e-02,  4.3861e-02,  5.1988e-02,  5.9468e-02,\n",
       "                       4.4001e-02,  8.0501e-02,  7.8583e-03,  6.8329e-02,  6.5594e-02,\n",
       "                       6.6390e-02,  3.5489e-02,  8.8466e-03,  9.1448e-03,  7.4335e-02,\n",
       "                       4.6795e-02,  5.3123e-02, -2.5446e-02,  5.1000e-02,  5.8165e-02,\n",
       "                       6.3242e-02,  5.8074e-02,  7.1310e-02,  6.0385e-02,  2.3553e-03,\n",
       "                       4.0317e-02,  4.4558e-02,  5.5558e-02,  2.3601e-02,  6.3080e-02,\n",
       "                       4.9239e-02,  8.8268e-02,  4.9470e-02,  4.5206e-02,  8.5114e-02,\n",
       "                       6.4628e-02,  2.7848e-02,  3.5461e-02,  3.4611e-02,  7.8741e-02,\n",
       "                       9.0596e-03,  3.6457e-02,  4.5815e-02,  4.9471e-02,  2.0531e-02,\n",
       "                       4.5715e-02,  5.7914e-02,  7.6731e-02,  1.5877e-02,  4.7518e-02,\n",
       "                       1.7021e-02,  4.7494e-02, -6.0447e-02,  6.8404e-02,  1.7218e-02,\n",
       "                       1.4152e-02,  4.5380e-02,  5.9791e-02,  7.4244e-02,  5.6742e-02,\n",
       "                       3.1535e-02,  4.7421e-02,  5.6538e-02,  1.0790e-02, -1.1043e-01,\n",
       "                       8.8585e-02,  9.8396e-02,  2.6898e-02,  8.3078e-02,  5.7278e-02,\n",
       "                       5.7470e-02,  5.6696e-02,  8.6951e-02,  4.4697e-02,  6.6670e-02,\n",
       "                       3.8889e-02, -1.3928e-01,  6.8364e-02,  7.9407e-03,  6.2071e-02,\n",
       "                      -1.2886e-01,  5.1547e-02,  5.8116e-02,  1.9377e-02,  1.7409e-02,\n",
       "                       2.4441e-02,  3.4420e-02,  6.3525e-02,  6.7246e-02,  8.6976e-02,\n",
       "                       4.7609e-02,  5.6562e-02,  6.7620e-02, -3.2967e-03,  1.6356e-02,\n",
       "                       5.9359e-02,  5.4976e-02,  5.6766e-02,  3.3565e-02,  6.2424e-02,\n",
       "                       2.0870e-02,  2.4566e-02,  5.9046e-02,  5.8906e-02,  7.9421e-02,\n",
       "                       4.5873e-02,  6.7747e-02,  2.0637e-02,  4.5976e-02,  4.8253e-02,\n",
       "                       7.1643e-02,  2.4303e-02, -1.0599e-01,  4.4671e-02,  6.1684e-02,\n",
       "                       4.7356e-02,  7.3685e-02,  3.3994e-02,  6.0061e-02,  5.1065e-02,\n",
       "                       4.8735e-02,  1.3853e-02,  6.8872e-02,  1.1833e-02,  1.2850e-01,\n",
       "                       6.5312e-02,  5.3068e-02,  2.4986e-02,  2.1563e-02,  5.3587e-02,\n",
       "                       6.3070e-02,  5.7518e-02,  6.7714e-02,  7.9044e-03,  1.5801e-02,\n",
       "                       5.2752e-02,  9.7497e-03,  7.0446e-02,  6.0824e-02,  5.9480e-02,\n",
       "                       7.2170e-03,  6.7416e-02,  5.8228e-02,  2.3491e-02,  4.8757e-02,\n",
       "                       7.6745e-02,  1.0563e-02,  9.2335e-02,  4.4782e-02, -8.6694e-02,\n",
       "                       1.6268e-02,  7.7398e-02,  6.1103e-02,  1.2134e-02,  6.2762e-02,\n",
       "                       7.2825e-02,  3.8329e-02,  6.7006e-02,  3.1479e-02,  8.1821e-02,\n",
       "                       4.5023e-02,  1.6949e-02,  4.4294e-02,  4.9565e-02,  5.2402e-02,\n",
       "                       6.1569e-02,  5.7506e-02,  4.5938e-02,  2.4036e-02,  6.8139e-02,\n",
       "                       5.6885e-02,  5.6029e-02,  8.0418e-02,  5.4144e-02,  1.1484e-02,\n",
       "                       6.8990e-02,  1.2927e-02,  2.9812e-02,  6.1350e-02,  4.6153e-02,\n",
       "                       7.0539e-02,  5.1079e-02,  6.2034e-02,  5.7485e-02,  4.9956e-02,\n",
       "                       1.1856e-01,  8.8596e-02,  2.7064e-02,  2.3460e-02, -8.2576e-02,\n",
       "                       4.8624e-02,  6.7723e-02,  1.3996e-02,  4.9030e-02,  1.9483e-02,\n",
       "                       3.5470e-02,  4.3191e-02,  2.8626e-02,  6.2757e-02,  2.7273e-02,\n",
       "                       5.0059e-02,  5.7217e-02,  2.0631e-02,  5.7980e-02,  5.1325e-02,\n",
       "                      -1.0036e-01,  3.2978e-02,  1.3106e-02,  4.5371e-02,  9.6515e-03,\n",
       "                       1.0350e-02,  5.4214e-02,  7.0568e-02,  8.8404e-03,  5.9632e-02,\n",
       "                       4.2914e-02,  1.4907e-02,  1.9115e-02,  2.9410e-02,  1.0288e-01,\n",
       "                       5.0237e-02,  5.8552e-02,  1.8448e-02,  3.1479e-02,  5.2876e-02,\n",
       "                       2.2321e-02,  6.4071e-02,  5.5910e-02,  6.4453e-02,  2.8222e-02,\n",
       "                       5.6038e-02,  5.3997e-02,  5.0697e-02,  2.2658e-02, -5.8925e-02,\n",
       "                       6.0181e-02,  6.3407e-02,  4.6221e-02,  4.5792e-02,  1.9229e-02,\n",
       "                       3.5318e-02,  5.5814e-02,  6.8949e-02,  4.4033e-02,  2.9608e-02,\n",
       "                       6.4862e-02,  2.1286e-02,  3.1107e-02,  1.8579e-02,  6.4483e-02,\n",
       "                       4.1054e-02,  4.2707e-02,  5.6006e-02,  1.1601e-01,  5.5854e-02,\n",
       "                       5.4698e-02,  1.7523e-02,  8.3134e-02,  5.2604e-02,  3.6672e-02,\n",
       "                       4.2296e-02,  6.4536e-02,  2.2511e-02,  2.6179e-02,  3.0052e-02,\n",
       "                       4.0828e-02,  5.8790e-02,  1.6186e-02,  4.2965e-02,  3.8535e-02,\n",
       "                       6.6656e-02,  5.5514e-02,  5.5860e-02,  1.0316e-01,  4.1157e-02,\n",
       "                       6.6292e-02,  1.5019e-02,  2.0473e-02,  9.4857e-02,  4.4174e-02,\n",
       "                       2.6409e-02,  6.4904e-02,  2.7857e-02,  4.9059e-02,  6.6147e-02,\n",
       "                       8.7286e-02,  3.3727e-02,  6.1490e-02,  2.0392e-02,  3.2749e-02,\n",
       "                       4.5414e-02,  6.5175e-03,  2.2218e-02,  8.4498e-02,  7.0440e-02,\n",
       "                       6.7003e-02,  4.2546e-04,  6.8871e-02,  1.1402e-03,  5.7056e-02,\n",
       "                       1.0149e-01,  3.8032e-02,  6.7862e-02], device='cuda:0')),\n",
       "             ('predictions.transform.LayerNorm.weight',\n",
       "              tensor([ 2.6050,  2.6149,  2.7081,  2.7050,  2.4920,  2.7489,  2.5248,  2.7545,\n",
       "                       2.5978,  2.4810,  2.2662,  2.5568,  2.6377,  2.1540,  2.4226,  2.4589,\n",
       "                       2.5572,  2.3579,  2.3851,  2.7082,  2.7463,  2.3740,  2.5781,  2.3975,\n",
       "                       2.4010,  2.5122,  2.3575,  2.6579,  2.3965,  2.5778,  2.6456,  2.4955,\n",
       "                       2.3458,  2.7889,  2.5711,  2.7190,  2.7664,  2.5873,  2.4641,  2.3293,\n",
       "                       2.7963,  2.6165,  2.5932,  2.5698,  2.4873,  2.5118,  2.5971,  2.8377,\n",
       "                       2.4723,  2.6113,  2.5926,  2.3830,  2.5688,  0.5782,  2.5231,  2.4652,\n",
       "                       2.3997,  2.3558,  2.3963,  2.3040,  2.4666,  2.3836,  0.5474,  2.3870,\n",
       "                       2.6355,  2.4671,  2.2829,  2.6707,  2.4731,  2.5831,  2.6564,  2.6723,\n",
       "                       2.7696,  2.3226,  2.7429,  2.2812,  2.3631,  0.1607,  2.2782,  2.7579,\n",
       "                       2.5907,  2.7728,  2.4256,  2.3151,  2.3265,  2.4077,  2.3335,  2.5196,\n",
       "                       2.4776,  2.7233,  2.4859,  2.3075,  2.4377,  2.3267,  2.5034,  2.5339,\n",
       "                       0.3293,  2.2641,  2.5728,  2.5414,  2.7218,  2.7926,  2.2730,  2.5781,\n",
       "                       2.6352,  0.5399,  2.5463,  2.7792,  2.3344,  2.3596,  2.7955,  2.3890,\n",
       "                       2.4035,  2.7431,  2.4772,  2.3720,  2.3911,  2.7092,  2.6123,  2.4277,\n",
       "                       2.4268, -0.2033,  2.6166,  2.8295,  2.7141,  2.5203,  2.4085,  3.7366,\n",
       "                       2.7043,  2.7558,  2.4806,  2.5406,  0.3513,  2.2225,  2.7450,  2.8502,\n",
       "                       2.5108,  2.3526,  2.3736,  0.5970,  2.6414,  2.5164,  2.6619,  2.4381,\n",
       "                       2.4644,  2.3316,  2.6842,  2.5230,  2.7188,  2.4822,  2.4818,  2.6256,\n",
       "                       2.3943,  2.5702,  2.5717,  2.5366,  2.4801,  2.4558,  2.7802,  0.4657,\n",
       "                       2.6438,  2.5436,  2.2556,  3.0290,  2.7154,  2.8616,  2.3204,  2.3815,\n",
       "                       0.6648,  2.8902,  2.6607,  2.2177,  2.2085,  2.7202,  2.6033,  0.5835,\n",
       "                       2.4506,  2.8966,  2.2116,  2.4445,  2.5008,  2.7027,  2.5916,  2.7341,\n",
       "                       2.4680,  2.5926,  2.7816,  2.6085,  2.6479,  2.4261,  2.4553,  2.6041,\n",
       "                       2.5731,  2.5980,  2.6818,  2.7704,  2.5885,  2.5625,  2.6404,  2.6086,\n",
       "                       2.7195,  2.4402,  1.0337,  2.6625,  2.6324,  2.4592,  2.5160,  2.2633,\n",
       "                       2.7775,  2.3484,  2.6762,  2.5654,  2.3552,  2.4531,  2.4710,  0.6909,\n",
       "                       0.7300,  2.4494,  0.5406,  2.3840,  2.4872,  2.5051,  2.6659,  2.3855,\n",
       "                       2.5807,  0.5001,  2.4645,  2.5136,  2.4697,  2.7555,  2.6397,  2.4996,\n",
       "                       2.6042,  2.4998,  2.7201,  2.5990,  2.4492,  2.2468,  2.5488,  2.5957,\n",
       "                       2.4561,  2.5961,  2.5630,  2.6414,  2.7566,  0.4916,  2.2915,  2.4243,\n",
       "                       2.2822,  1.1666,  2.5558,  2.6922,  2.5858,  2.3541,  2.6146,  2.3397,\n",
       "                       2.4749,  2.3367,  2.3120,  2.3921,  2.6669,  2.5792,  2.4721,  2.5609,\n",
       "                       2.6758,  2.7041,  2.5262,  2.6411,  2.7133,  2.6054,  2.5980,  2.5901,\n",
       "                       2.3499,  2.5598,  2.7765,  2.5766,  2.2377,  2.5019,  2.4302,  2.6227,\n",
       "                       2.3803,  2.4620,  2.8692,  0.4298,  2.3810,  2.3540,  2.5803,  2.8095,\n",
       "                       2.6946,  2.6870,  2.8641,  0.5797,  2.4665,  2.5294,  2.5703,  2.4239,\n",
       "                       0.4510,  2.8039,  2.6643,  2.5068,  2.7347,  2.8003,  2.5989,  2.8462,\n",
       "                       2.6770,  2.3483,  2.5198,  2.5282, -0.1363,  2.4372,  2.6681,  0.6610,\n",
       "                       2.4375,  2.5522,  2.6173,  2.6779,  2.5963,  2.5662,  2.3257,  0.3695,\n",
       "                       2.5025,  2.2829,  2.5518,  2.5428,  2.4711,  2.4729,  2.3676,  2.6400,\n",
       "                       2.5491,  2.3038,  2.4158,  0.6030,  2.4143,  2.7582,  2.7015,  2.3628,\n",
       "                       2.2533,  2.5378,  2.7745,  2.6907,  2.3987,  2.8027,  2.7534,  2.5095,\n",
       "                       2.3250,  0.1704,  2.7541,  2.5131,  2.5951,  2.5324,  2.5988,  2.6576,\n",
       "                       2.6016,  0.4239,  2.7048,  2.6744,  2.5928,  2.4626,  2.3903,  2.3660,\n",
       "                       2.5967,  2.6534,  2.2946,  2.6740,  2.4148,  2.6126,  2.5620,  2.4046,\n",
       "                       2.7027,  2.6703,  2.4846,  2.4464,  2.4549,  2.5284,  2.6374,  2.5965,\n",
       "                       2.6758,  2.3919,  2.5993,  2.6626,  2.4097,  2.4653,  2.6577,  2.4570,\n",
       "                       2.7469,  2.6392,  2.3985,  2.8495,  2.4756,  2.4837,  3.0243,  2.3883,\n",
       "                       2.4881,  2.3757,  2.6383,  2.6119,  2.5671,  2.4527,  2.6102,  2.6383,\n",
       "                       2.4191,  2.4206,  2.4844,  2.7296,  2.5990,  2.3821,  2.6280,  2.4722,\n",
       "                       2.4860,  2.4318,  2.7339,  2.6370,  2.6755,  3.0960,  2.3270,  2.4034,\n",
       "                       2.5213,  2.6287,  2.4315,  0.0952,  2.4309,  2.4060,  2.7188,  2.7627,\n",
       "                       2.5802,  2.6286,  2.5954,  3.0529,  2.6978,  2.7621,  2.5928,  2.6158,\n",
       "                       2.7374,  2.2759,  2.4366,  2.7856,  2.4512,  2.4386,  2.5196,  2.4211,\n",
       "                       2.4842,  2.4061,  2.6786,  0.0194,  2.4176,  2.5833,  2.6978,  2.5270,\n",
       "                       2.5416,  2.6470,  2.2625,  2.7502,  2.6684,  2.5595,  2.7345,  2.7573,\n",
       "                       2.5145,  2.4344,  2.4040,  2.5075,  2.5851,  0.4531,  2.6548,  2.4038,\n",
       "                       2.6371,  2.6711,  2.4547,  2.4807,  2.2972,  2.5773,  2.4821,  2.8265,\n",
       "                       2.6332,  2.4377,  2.6005,  2.3101,  2.3211,  2.6919,  2.4344,  2.3837,\n",
       "                       2.7081,  2.2785,  0.6112,  2.3719,  2.4585,  2.2612,  2.4076,  2.5890,\n",
       "                       2.4517,  2.6191,  2.6446,  2.5992,  2.4869,  2.8156,  2.6132,  2.5107,\n",
       "                       0.6777,  2.3051,  2.7596,  2.6470,  2.2461,  2.6820,  2.6005,  2.5909,\n",
       "                       2.2828,  3.2313,  2.6528,  2.4106,  2.4783,  2.6113,  2.2981,  2.3463,\n",
       "                       2.4460,  2.6236,  2.4316,  2.7084,  2.4367,  0.5380,  2.3990,  2.3912,\n",
       "                       2.7249,  2.2249,  2.3786,  2.3277,  2.3228,  2.5368,  2.5690,  2.7331,\n",
       "                       2.4542,  0.7668,  2.5897,  2.6447,  2.7314,  2.3829,  2.6058,  2.4829,\n",
       "                       2.4348,  2.4800,  2.4709,  2.3771,  2.7268,  0.5505,  2.5273,  2.4213,\n",
       "                       2.4363,  0.7345,  2.3044,  2.5771,  2.7030,  2.5287,  2.6577,  2.3365,\n",
       "                       2.7027,  2.6134,  2.4917,  2.7111,  2.4161,  2.3034,  2.7426,  2.6863,\n",
       "                       2.5271,  2.4687,  2.3097,  2.8004,  2.3777,  2.5630,  2.5878,  2.4571,\n",
       "                       2.7069,  2.5802,  2.5242,  2.5910,  2.6871,  2.3762,  2.4710,  2.2952,\n",
       "                       2.6952,  0.3832,  2.4963,  2.6030,  2.3930,  2.5704,  2.7334,  2.3400,\n",
       "                       2.4522,  2.4343,  2.7528,  2.8557,  2.6377,  2.5773,  2.7000,  2.5298,\n",
       "                       2.7123,  2.6584,  2.3147,  2.3200,  2.3379,  2.5581,  2.6822,  2.5593,\n",
       "                       2.5234,  2.7038,  2.5839,  2.3342,  2.3358,  2.5766,  2.7227,  2.4803,\n",
       "                       2.5929,  2.2895,  2.6706,  2.6536,  2.6756,  2.4351,  0.4626,  2.6274,\n",
       "                       2.4020,  2.7636,  2.7817,  2.3425,  2.4628,  2.5528,  2.5325,  2.6468,\n",
       "                       2.6270,  2.5382,  2.6443,  2.4351,  2.3253,  2.5953,  2.6235,  2.3665,\n",
       "                       2.3525,  2.6785,  2.3591,  2.4662,  2.4475,  2.6258,  2.3535,  2.6699,\n",
       "                       2.2960,  2.5743,  2.5435,  2.3324,  2.5068,  2.4618,  2.7661,  2.5502,\n",
       "                       2.5715,  2.3928,  2.6707,  2.6666,  2.4556,  2.5052,  0.7490,  2.3989,\n",
       "                       2.5387,  2.6596,  2.5266,  2.6623,  2.5958,  2.6703,  2.6558,  2.5098,\n",
       "                       2.5894,  2.5630,  2.4776,  2.5720,  2.3313,  2.5832,  0.0103,  2.5756,\n",
       "                       2.6850,  2.3247,  2.6881,  2.3623,  2.6710,  2.6055,  2.7934,  2.5233,\n",
       "                       2.5670,  2.5958,  2.6279,  2.4748,  2.7595,  2.4178,  2.3708,  2.7543,\n",
       "                       2.6598,  2.4330,  2.5284,  2.2795,  2.3871,  2.7359,  2.6240,  2.4161,\n",
       "                       2.3137,  2.3511,  2.4020,  0.6278,  2.6736,  2.2279,  2.5249,  3.0057,\n",
       "                       2.5888,  2.4195,  2.2931,  2.3405,  2.5056,  2.7191,  2.3829,  2.7094,\n",
       "                       2.4664,  2.6481,  2.4675,  2.8038,  2.5291,  2.3946,  2.5121,  2.3705,\n",
       "                       2.3834,  2.4867,  2.5240,  2.4805,  2.6719,  2.6309,  2.2609,  2.4234,\n",
       "                       2.5324,  2.5772,  2.7017,  2.4828,  2.7818,  2.7236,  3.0166,  2.3606,\n",
       "                       2.4240,  2.3134,  2.5594,  2.3134,  2.4490,  2.5828,  2.8046,  2.5408,\n",
       "                       2.3981,  2.5805,  2.3749,  2.3330,  2.5322,  2.3621,  2.7677,  2.4974,\n",
       "                       2.2966,  2.7621,  2.5135,  2.3242,  2.3473,  2.6051,  2.5233,  2.2958,\n",
       "                       2.4564,  2.7228,  2.5089,  2.7682,  2.3446,  2.6525,  2.6309,  2.8759],\n",
       "                     device='cuda:0')),\n",
       "             ('predictions.transform.LayerNorm.bias',\n",
       "              tensor([-3.7120e-01,  2.3995e-01,  1.6037e-01,  2.5400e-01, -3.9031e-01,\n",
       "                       1.7627e-01,  2.6477e-01,  1.9510e-01,  2.5817e-02,  2.7539e-01,\n",
       "                       9.3122e-02,  4.3223e-01,  4.6328e-01, -5.7503e-01, -4.2663e-01,\n",
       "                       3.2155e-01,  3.7901e-01,  1.2883e-01, -1.4197e-01,  2.5800e-01,\n",
       "                       1.9080e-01, -8.8919e-02,  1.6684e-01, -1.1515e-01,  7.0450e-01,\n",
       "                       2.4303e-01, -5.2949e-01, -4.7142e-02, -3.4216e-01,  1.0103e-01,\n",
       "                       9.2652e-02, -2.0200e-01, -3.2266e-01, -2.7509e-01,  2.7833e-01,\n",
       "                       3.5113e-01,  4.2490e-01, -2.5969e-01,  2.2576e-01, -2.5473e-01,\n",
       "                       1.9421e-01,  9.7177e-02,  3.2932e-01, -2.3517e-01, -8.6305e-02,\n",
       "                      -3.5294e-01,  1.0746e-01,  2.3124e-01, -2.3298e-01,  2.4829e-01,\n",
       "                      -2.4602e-01, -3.6509e-01,  1.0341e-01,  2.9882e-01, -2.9058e-02,\n",
       "                      -1.6423e-01, -2.1945e-01, -2.7949e-01, -1.4167e-01, -2.6651e-01,\n",
       "                      -2.6700e-01, -1.5618e-01,  3.4209e-01,  7.5217e-03,  3.6024e-01,\n",
       "                      -3.6539e-01, -1.8883e-01,  1.4791e-01, -2.0336e-01,  2.4324e-01,\n",
       "                      -1.5434e-01, -9.6027e-02,  2.0246e-01,  2.5734e-01,  7.6976e-01,\n",
       "                      -3.5689e-01,  5.7697e-01, -2.5372e-01, -2.6671e-01,  4.1669e-01,\n",
       "                       2.8495e-01,  7.0274e-02, -1.0822e-01, -1.0497e-01, -1.4480e-02,\n",
       "                      -1.9129e-01, -1.1796e-01,  2.0516e-01, -2.4585e-01,  1.4859e-01,\n",
       "                       9.1981e-02, -2.6965e-01,  2.5721e-01, -3.1808e-01,  3.1798e-01,\n",
       "                       3.8449e-01, -1.3505e-02,  4.5799e-02,  4.7314e-01,  3.0403e-01,\n",
       "                       1.4992e-01, -9.5037e-02, -2.9161e-01, -1.1077e-01,  2.6070e-01,\n",
       "                       4.0679e-01, -1.1672e-01,  1.2596e-01, -3.6875e-01, -2.0890e-01,\n",
       "                       4.2995e-01, -2.1469e-01,  3.3959e-03,  1.7064e-01, -6.0722e-02,\n",
       "                      -3.9035e-01, -4.0457e-01,  2.6659e-01,  2.9336e-01, -1.0168e-01,\n",
       "                      -2.3250e-01, -4.2251e-01, -1.6667e-01,  2.2715e-01,  3.6009e-01,\n",
       "                      -2.6557e-02, -1.6918e-01,  7.0544e-01,  3.4535e-01,  4.5528e-01,\n",
       "                      -2.4379e-01, -9.9478e-03,  4.5853e-02, -3.7596e-01,  1.9678e-01,\n",
       "                       3.3548e-01, -1.1800e-01, -2.5174e-01, -3.1415e-01,  3.1263e-01,\n",
       "                       8.3532e-02, -1.6932e-01,  3.7383e-01, -4.2816e-01, -3.2904e-01,\n",
       "                      -3.9614e-01,  3.2158e-01,  1.4857e-01,  4.1096e-01,  8.3654e-02,\n",
       "                      -3.7823e-02,  5.2673e-01,  9.8098e-01,  1.6814e-01,  2.0921e-03,\n",
       "                      -6.2586e-02,  6.0616e-04,  8.0163e-02,  1.9143e-01,  2.3548e-01,\n",
       "                       7.0280e-02, -2.2682e-01, -2.2685e-01,  3.6653e-01,  2.6560e-01,\n",
       "                       2.3185e-01, -3.3597e-01, -2.2077e-01,  1.3035e-01,  1.4262e-01,\n",
       "                       2.5464e-01, -5.3974e-01, -3.1841e-01,  1.6410e-01, -3.5155e-02,\n",
       "                       1.9347e-01, -1.8052e-01,  3.5945e-01, -3.8370e-01, -4.7299e-01,\n",
       "                       1.5205e-02,  3.6007e-01,  6.7207e-01,  1.6334e-01, -2.9381e-01,\n",
       "                       1.3120e-01,  5.2729e-02,  3.7884e-01,  7.5253e-02, -4.5890e-01,\n",
       "                      -3.0389e-01,  1.8049e-01,  7.0706e-01,  3.6247e-01,  2.3318e-01,\n",
       "                       3.4145e-01,  1.5659e-02, -1.7385e-01,  3.1563e-01,  3.9017e-01,\n",
       "                       2.6850e-01, -2.1567e-01,  6.7699e-01,  3.7232e-01,  3.6866e-01,\n",
       "                      -4.4767e-01, -3.9508e-01, -4.6969e-02,  3.9008e-01, -8.3131e-02,\n",
       "                       1.0676e-01,  2.5237e-01, -2.9362e-01,  7.6498e-02, -2.7413e-01,\n",
       "                       4.7908e-01,  4.7127e-01, -1.5569e-01,  3.4559e-01, -9.7203e-02,\n",
       "                      -3.2824e-01,  1.6682e-01,  9.6137e-02, -1.6670e-01,  3.5492e-01,\n",
       "                       2.5961e-01, -1.5100e-02,  3.3017e-02, -3.2135e-01,  3.9142e-01,\n",
       "                       2.2814e-01,  3.7159e-01,  4.8037e-01,  1.9533e-01,  2.9554e-01,\n",
       "                      -3.2699e-01, -2.4258e-01, -3.1280e-01, -2.0679e-02,  2.1943e-01,\n",
       "                       2.5828e-01,  1.5229e-01,  2.4940e-01,  4.8839e-01,  1.9067e-01,\n",
       "                       2.5548e-01, -3.1673e-01,  1.9591e-01, -1.6647e-01,  1.1208e+00,\n",
       "                       5.2908e-01,  1.0517e-01, -6.2531e-02, -2.2256e-01, -1.5963e-01,\n",
       "                      -4.4672e-01, -9.1588e-02,  1.4291e-01, -3.3344e-01, -2.5237e-01,\n",
       "                       1.3340e-02,  3.0726e-01, -2.8000e-01,  1.3640e-01,  4.0861e-01,\n",
       "                       2.9899e-01,  7.3792e-02,  1.4610e-01,  2.5222e-01,  2.5797e-01,\n",
       "                       2.2229e-01, -4.7066e-02, -1.9267e-01,  3.3789e-01,  2.1988e-01,\n",
       "                      -8.6082e-02, -1.7416e-01,  2.5210e-01, -2.3884e-01,  2.1683e-01,\n",
       "                      -1.8993e-01, -2.4701e-01, -1.4146e-01,  2.8200e-01, -1.6481e-01,\n",
       "                       6.2963e-01,  3.5408e-01,  9.1780e-02,  4.7843e-02,  1.0088e-01,\n",
       "                       6.2787e-01,  2.9871e-01, -3.8084e-01, -7.6712e-02,  2.3685e-01,\n",
       "                      -2.5885e-01,  2.9011e-01,  3.9046e-01,  3.8103e-01,  1.9245e-01,\n",
       "                       3.5531e-01, -2.2828e-01,  7.6565e-02,  2.0208e-01,  4.8979e-01,\n",
       "                      -3.5716e-01, -8.8310e-03,  1.7679e-01, -2.0681e-01,  2.2734e-01,\n",
       "                       1.2409e-01,  1.8594e-01, -3.4570e-01,  4.8769e-01,  2.9638e-01,\n",
       "                       3.7229e-01,  2.6474e-01,  4.7011e-02, -3.9834e-01,  1.0049e-01,\n",
       "                       1.9997e-03, -3.5591e-01,  7.4946e-02, -2.4312e-01,  4.8458e-01,\n",
       "                      -3.0711e-01, -2.6865e-01,  1.7948e-01, -9.9845e-02, -3.5821e-01,\n",
       "                       1.6262e-01,  2.5842e-01,  6.7880e-01,  2.1025e-01,  2.1426e-01,\n",
       "                      -2.9999e-01, -3.4538e-01,  1.2381e-01,  1.9915e-01,  1.1690e-01,\n",
       "                       5.2674e-02,  1.5947e-01, -5.8026e-01,  2.0726e-02, -4.9910e-01,\n",
       "                      -1.7502e-01,  1.1566e-01,  4.4426e-01,  3.0165e-01, -2.5293e-01,\n",
       "                       9.6770e-02,  6.4321e-02,  2.0342e-01,  1.7120e-01,  3.7345e-01,\n",
       "                       3.5579e-01,  2.1206e-01, -3.8162e-01,  5.4206e-02, -2.5952e-01,\n",
       "                       1.4133e-01, -1.7631e-01, -4.2189e-01,  6.1224e-02, -3.4736e-01,\n",
       "                       2.5668e-01, -1.1772e-01, -3.1047e-01,  3.5472e-01,  3.6739e-01,\n",
       "                      -1.1129e-01,  2.5976e-01, -2.2264e-01,  8.3626e-02,  6.0041e-01,\n",
       "                       2.6480e-01,  2.0998e-01, -1.3438e-01,  4.2144e-01,  1.8163e-02,\n",
       "                      -8.1918e-02,  2.4485e-01,  3.3356e-01, -8.9416e-02,  1.0838e-01,\n",
       "                       2.7573e-01, -2.3200e-01,  1.0152e-01, -2.1942e-01, -4.9830e-02,\n",
       "                      -2.3537e-01, -1.4809e-03,  2.5535e-01,  1.4236e-01,  4.7998e-01,\n",
       "                       1.9420e-01,  1.3073e-01, -3.1142e-01,  5.7741e-01,  2.1134e-01,\n",
       "                      -5.5642e-01,  1.3877e+00, -1.2497e-01,  3.3897e-01, -1.6990e-02,\n",
       "                      -3.3011e-01,  1.4118e-02, -1.3955e-01, -3.5043e-01, -1.6967e-01,\n",
       "                       2.3313e-01,  3.3014e-01,  2.3531e-01,  4.7171e-01, -2.2379e-01,\n",
       "                      -2.7574e-01,  4.6898e-01,  3.1536e-01, -2.7172e-01, -2.0358e+00,\n",
       "                      -4.0200e-01, -1.6099e-01,  5.8162e-02,  3.2545e-01,  2.9468e-01,\n",
       "                       1.7757e-01, -3.6787e-02,  3.2744e-01,  3.8580e-01,  9.3945e-01,\n",
       "                       2.1816e-01,  1.1263e-01,  3.0631e-01, -4.3457e-01, -3.5458e-01,\n",
       "                       2.3365e-01, -1.1271e-01,  7.1565e-02, -2.5419e-01, -3.2048e-01,\n",
       "                      -1.3431e-01, -3.7494e-01,  1.3522e-01, -2.7145e-01, -2.1768e-01,\n",
       "                       2.2976e-01,  4.8030e-01,  1.6847e-02,  2.6222e-01, -7.8454e-02,\n",
       "                      -3.5021e-01,  1.1438e-01,  1.5030e-01, -3.3396e-02,  1.9781e-01,\n",
       "                       2.5926e-01,  2.6166e-01, -4.3289e-01, -5.3386e-02, -4.6090e-02,\n",
       "                       2.4185e-01,  4.4186e-01,  1.8748e-01, -2.5994e-02,  7.0501e-02,\n",
       "                       2.9672e-01, -2.9005e-01, -3.2951e-01, -5.9082e-01,  2.1058e-01,\n",
       "                      -6.0983e-02,  6.7183e-02,  6.3643e-01, -3.3415e-01,  2.3080e-01,\n",
       "                      -1.5919e-01, -3.9875e-01,  1.3545e-01, -4.5270e-02, -8.7202e-02,\n",
       "                      -1.1359e-02, -4.7818e-01,  3.6935e-01, -3.3615e-01, -4.1700e-02,\n",
       "                      -1.4483e-01, -2.4701e-01,  3.5446e-01, -2.5168e-01, -1.3466e-01,\n",
       "                       2.1657e-01,  2.9390e-01, -2.6937e-01,  4.8906e-01, -1.0394e-02,\n",
       "                      -2.0262e-01,  7.9523e-01, -3.2074e-01,  5.3277e-01,  3.2450e-01,\n",
       "                      -3.0197e-01,  4.6439e-01,  3.6871e-01,  6.8420e-01,  2.3733e-01,\n",
       "                       3.1874e-01,  4.2929e-01, -1.3013e-01,  9.4728e-03,  1.8771e-01,\n",
       "                      -3.4849e-02,  2.4463e-01,  4.5833e-02,  3.6469e-01, -1.7234e-01,\n",
       "                       2.5196e-01, -2.4074e-01,  1.4518e-01,  2.7111e-01,  5.8546e-02,\n",
       "                       1.9672e-01, -5.5933e-02, -2.5808e-01, -2.7674e-01, -1.3009e-01,\n",
       "                      -1.4882e-01,  1.7697e-01,  4.6856e-01,  3.0904e-01,  1.6548e-01,\n",
       "                       1.5894e-01,  1.2594e-01,  1.6814e-01, -1.7961e-01,  2.3311e-01,\n",
       "                      -3.9432e-02,  1.4964e-02,  2.4036e-01,  1.3814e-02,  1.3934e-02,\n",
       "                       2.3040e-01,  1.3038e-01, -7.7532e-02,  7.7327e-02, -7.3919e-02,\n",
       "                       3.7418e-01, -4.3127e-01,  3.9411e-01,  3.3226e-01, -2.2833e-01,\n",
       "                       2.7466e-01, -2.6489e-01,  1.7338e-01,  1.0187e-01, -3.1895e-02,\n",
       "                      -1.3497e-01, -3.4085e-01, -3.2811e-01,  2.4780e-01,  3.9660e-01,\n",
       "                       1.7151e-01, -3.7133e-01, -3.7840e-01,  4.8204e-01, -2.9764e-01,\n",
       "                      -2.2017e-01,  1.0931e-01, -9.6898e-03,  8.7319e-02, -2.3257e-01,\n",
       "                       1.1675e-02,  1.5719e-01,  1.3483e-01, -4.5001e-01, -4.3000e-01,\n",
       "                      -2.0034e-01,  2.4174e-01,  2.5889e-02, -1.7075e-01,  1.0850e-01,\n",
       "                      -3.6422e-01,  2.2868e-01,  3.5980e-01, -4.5218e-01, -1.6455e-01,\n",
       "                      -4.0053e-01,  1.3961e-01,  2.2642e-01,  4.7915e-01,  3.6381e-01,\n",
       "                       2.0854e-01,  2.3782e-01,  5.2520e-02,  3.9917e-01, -2.4638e-01,\n",
       "                      -4.8317e-01, -7.3621e-02, -6.7207e-02,  1.7670e-01, -1.8248e-01,\n",
       "                       1.9043e-01, -3.4951e-02,  1.1138e-01, -3.8493e-01, -2.4722e-01,\n",
       "                       2.2794e-01,  1.3746e-01,  2.0660e-01,  2.4410e-01, -4.0552e-02,\n",
       "                       4.2943e-01,  3.1155e-01,  9.1385e-02, -2.9752e-01,  1.9198e-01,\n",
       "                       2.8592e-01, -1.2460e-01,  1.1230e-01,  4.8250e-01, -3.8489e-01,\n",
       "                       1.1186e-01,  2.6676e-01, -1.5032e-01,  2.6797e-01, -3.4646e-01,\n",
       "                       9.5570e-02,  8.3232e-02, -2.6019e-01, -2.2477e-01,  8.0652e-03,\n",
       "                       2.7280e-01, -9.3166e-02, -1.6275e-01,  2.4982e-01, -3.7925e-01,\n",
       "                      -3.0160e-01, -4.4091e-01,  7.4727e-02, -2.4407e-01,  4.6361e-01,\n",
       "                      -3.6789e-02, -5.7043e-02,  3.7469e-01, -3.1325e-01, -1.7143e-01,\n",
       "                      -1.4841e-01,  1.6527e-01,  3.6650e-01, -2.6787e-01, -3.8448e-01,\n",
       "                       1.4357e-01,  4.1413e-01, -4.6146e-03,  2.8752e-01,  1.6228e-01,\n",
       "                      -4.9923e-01, -1.8033e-01,  2.2664e-01, -2.5673e-01,  4.5212e-01,\n",
       "                       2.5572e-01,  3.7102e-01,  2.7745e-01,  2.3868e-01,  3.6773e-01,\n",
       "                       2.8219e-01, -2.7115e-01,  3.0693e-02, -1.5002e-01,  8.7810e-02,\n",
       "                      -1.9144e-01,  1.7728e-01,  5.6834e-02, -2.0317e-01,  3.3237e-01,\n",
       "                      -4.4118e-01,  2.4458e-01,  3.4905e-02,  1.3304e-01, -8.5914e-02,\n",
       "                       5.2901e-02,  2.3703e-01,  2.0904e-01, -2.9598e-01,  1.5311e-01,\n",
       "                       1.2090e-01, -2.2627e-01,  1.8634e-01,  2.8612e-01, -4.6476e-01,\n",
       "                      -1.6950e-01, -3.4677e-01, -1.2894e-01,  1.4846e-01,  3.1863e-01,\n",
       "                       3.4875e-01, -3.3601e-01, -1.4068e-01, -2.8962e-01,  4.8277e-01,\n",
       "                       2.0620e-01, -3.8357e-01,  3.2569e-01,  7.1665e-01,  4.7992e-01,\n",
       "                       7.1893e-03, -1.8401e-01, -1.7643e-01,  2.3081e-01,  1.7345e-01,\n",
       "                      -4.3975e-01,  2.2318e-01, -4.1314e-01,  1.7256e-01, -3.0199e-01,\n",
       "                       2.5966e-01, -2.0711e-02, -2.4207e-01,  7.4629e-02, -3.2979e-01,\n",
       "                       8.3288e-02, -1.1741e-01,  6.7549e-02,  1.4638e-01,  1.1391e-01,\n",
       "                       1.5181e-01, -9.6478e-02, -2.6409e-01,  3.7338e-01,  4.9064e-02,\n",
       "                       3.7406e-01, -2.0685e-01,  3.4213e-02,  3.8928e-01,  2.8435e-01,\n",
       "                      -3.0510e-01, -2.7585e-01, -4.4327e-01,  2.8030e-01, -4.0566e-01,\n",
       "                       2.7376e-01, -1.6962e-02,  4.8952e-02,  2.2024e-01,  8.2728e-02,\n",
       "                       9.5014e-02, -2.1998e-01, -1.5826e-01, -2.1514e-01, -4.1918e-01,\n",
       "                       1.2381e-01,  3.5494e-03, -3.5258e-01,  3.2851e-01,  5.6374e-01,\n",
       "                      -4.5069e-01,  2.2768e-01, -2.0261e-01,  2.6813e-01, -8.8634e-03,\n",
       "                      -1.0068e-01,  1.8183e-01, -5.7969e-02, -8.8116e-02, -7.7423e-02,\n",
       "                      -6.0671e-02,  1.4312e-01,  3.9643e-01], device='cuda:0')),\n",
       "             ('predictions.decoder.weight',\n",
       "              tensor([[ 0.0058, -0.0775,  0.0032,  ...,  0.0133, -0.0648,  0.0190],\n",
       "                      [-0.0194, -0.0515, -0.0417,  ..., -0.0205, -0.0310, -0.0216],\n",
       "                      [-0.0277, -0.0540, -0.0424,  ..., -0.0206, -0.0329, -0.0148],\n",
       "                      ...,\n",
       "                      [-0.0255, -0.0465, -0.0233,  ..., -0.0085, -0.0084, -0.0398],\n",
       "                      [-0.0454, -0.0466, -0.0121,  ...,  0.0107, -0.0139, -0.0288],\n",
       "                      [-0.0001, -0.0750, -0.0295,  ..., -0.0120, -0.0489,  0.0676]],\n",
       "                     device='cuda:0')),\n",
       "             ('predictions.decoder.bias',\n",
       "              tensor([-0.4030, -0.4316, -0.4306,  ..., -0.8043, -0.8011, -0.5078],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion.decoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0053d-e009-425e-80a6-986a798a9540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3-env]",
   "language": "python",
   "name": "conda-env-anaconda3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
